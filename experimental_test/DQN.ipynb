{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# DQNの解説\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "画像引用:  \n",
    "https://qiita.com/sugulu/items/3c7d6cbe600d455e853b\n",
    "\n",
    "### DQNの特徴\n",
    "- Q学習において状態行動テーブルを関数で表したもの.\n",
    "- 離散的な行動を扱うことができる.\n",
    "\n",
    "参考:  \n",
    "http://blog.syundo.org/post/20171208-reinforcement-learning-dqn-and-impl/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "### OpenAI gymのインストール\n",
    "\n",
    "githubのレポジトリを参考に, gymモジュールをインストールしてください.  \n",
    "https://github.com/openai/gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import renom as rm\n",
    "import matplotlib.pyplot as plt\n",
    "from renom.utility.initializer import Gaussian\n",
    "from renom.cuda import set_cuda_active\n",
    "from renom_rl.discrete.dqn import DQN\n",
    "from renom_rl.env import BaseEnv\n",
    "from gym.core import Env\n",
    "from PIL import Image\n",
    "from logging import getLogger, StreamHandler, DEBUG, FileHandler\n",
    "\n",
    "set_cuda_active(True)\n",
    "env = gym.make('BreakoutNoFrameskip-v4')\n",
    "\n",
    "class CustomEnv(BaseEnv):\n",
    "    \n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "        self.action_shape = 4\n",
    "        self.state_shape = (4, 84, 84)\n",
    "        self.previous_frames = []\n",
    "        self._reset_flag = True\n",
    "        self._last_live = 5\n",
    "        super(CustomEnv, self).__init__()\n",
    "    \n",
    "    def reset(self):\n",
    "        if self._reset_flag:\n",
    "            self._reset_flag = False\n",
    "            self.env.reset()\n",
    "        n_step = np.random.randint(4, 32+1)\n",
    "        for _ in range(n_step):\n",
    "            state, _, _ = self.step(self.env.action_space.sample())\n",
    "        return state\n",
    "    \n",
    "    def sample(self):\n",
    "        return self.env.action_space.sample()\n",
    "    \n",
    "    def render(self):\n",
    "        self.env.render()\n",
    "\n",
    "    def _preprocess(self, state):\n",
    "        resized_image = Image.fromarray(state).resize((84, 110)).convert('L')\n",
    "        image_array = np.asarray(resized_image)/255.\n",
    "        final_image = image_array[26:110]\n",
    "        # Confirm that the image is processed correctly.\n",
    "        # Image.fromarray(np.clip(final_image.reshape(84, 84)*255, 0, 255).astype(np.uint8)).save(\"test.png\")\n",
    "        return final_image\n",
    "    \n",
    "    def step(self, action):\n",
    "        state_list = []\n",
    "        reward_list = []\n",
    "        terminal = False\n",
    "        for _ in range(4):\n",
    "            # Use last frame. Other frames will be skipped.\n",
    "            s, r, t, info = self.env.step(action)\n",
    "            state = self._preprocess(s)\n",
    "            reward_list.append(r)\n",
    "            if self._last_live > info[\"ale.lives\"]:\n",
    "                t = True\n",
    "                self._last_live = info[\"ale.lives\"]\n",
    "                if self._last_live > 0:\n",
    "                    self._reset_flag = False\n",
    "                else:\n",
    "                    self._last_live = 5\n",
    "                    self._reset_flag = True\n",
    "            if t:\n",
    "                terminal = True\n",
    "                \n",
    "        if len(self.previous_frames) > 3:\n",
    "            self.previous_frames = self.previous_frames[1:] + [state]\n",
    "        else:\n",
    "            self.previous_frames += [state]\n",
    "        state = np.stack(self.previous_frames)\n",
    "        return state, np.array(np.sum(reward_list) > 0), terminal\n",
    "    \n",
    "custom_env = CustomEnv(env)\n",
    "q_network = rm.Sequential([rm.Conv2d(32, filter=8, stride=4, ignore_bias=True),\n",
    "                           rm.Relu(),\n",
    "                           rm.Conv2d(64, filter=4, stride=2, ignore_bias=True),\n",
    "                           rm.Relu(),\n",
    "                           rm.Conv2d(64, filter=3, stride=1, ignore_bias=True),\n",
    "                           rm.Relu(), \n",
    "                           rm.Flatten(), \n",
    "                           rm.Dense(512, ignore_bias=True),\n",
    "                           rm.Relu(),\n",
    "                           rm.Dense(custom_env.action_shape, ignore_bias=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = DQN(custom_env, q_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run random 5000 step for storing experiences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 001 avg_loss: 0.005 total_reward [train:20.000 test:11.000] e-greedy:0.002: 100%|██████████| 2000/2000 [00:30<00:00, 64.95it/s]\n",
      "epoch 002 avg_loss: 0.004 total_reward [train:21.000 test:16.000] e-greedy:0.004: 100%|██████████| 2000/2000 [00:31<00:00, 64.37it/s]\n",
      "epoch 003 avg_loss: 0.003 total_reward [train:15.000 test:13.000] e-greedy:0.005: 100%|██████████| 2000/2000 [00:31<00:00, 63.59it/s]\n",
      "epoch 004 avg_loss: 0.003 total_reward [train:24.000 test:16.000] e-greedy:0.007: 100%|██████████| 2000/2000 [00:31<00:00, 64.08it/s]\n",
      "epoch 005 avg_loss: 0.002 total_reward [train:18.000 test:9.000] e-greedy:0.009: 100%|██████████| 2000/2000 [00:31<00:00, 63.96it/s]\n",
      "epoch 006 each step reward:0.000:   1%|          | 14/2000 [00:00<00:29, 68.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 006 avg_loss: 0.004 total_reward [train:23.000 test:1.000] e-greedy:0.011: 100%|██████████| 2000/2000 [00:31<00:00, 63.55it/s]\n",
      "epoch 007 avg_loss: 0.003 total_reward [train:22.000 test:14.000] e-greedy:0.013: 100%|██████████| 2000/2000 [00:30<00:00, 65.21it/s]\n",
      "epoch 008 avg_loss: 0.003 total_reward [train:26.000 test:15.000] e-greedy:0.014: 100%|██████████| 2000/2000 [00:30<00:00, 64.89it/s]\n",
      "epoch 009 avg_loss: 0.003 total_reward [train:17.000 test:10.000] e-greedy:0.016: 100%|██████████| 2000/2000 [00:31<00:00, 69.96it/s]\n",
      "epoch 010 avg_loss: 0.003 total_reward [train:30.000 test:17.000] e-greedy:0.018: 100%|██████████| 2000/2000 [00:30<00:00, 65.21it/s]\n",
      "epoch 011 each step reward:0.000:   1%|          | 12/2000 [00:00<00:26, 73.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 17.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 011 avg_loss: 0.004 total_reward [train:15.000 test:20.000] e-greedy:0.020: 100%|██████████| 2000/2000 [00:31<00:00, 63.24it/s]\n",
      "epoch 012 avg_loss: 0.004 total_reward [train:21.000 test:8.000] e-greedy:0.022: 100%|██████████| 2000/2000 [00:32<00:00, 61.83it/s]\n",
      "epoch 013 avg_loss: 0.003 total_reward [train:22.000 test:14.000] e-greedy:0.023: 100%|██████████| 2000/2000 [00:30<00:00, 64.58it/s]\n",
      "epoch 014 avg_loss: 0.003 total_reward [train:24.000 test:13.000] e-greedy:0.025: 100%|██████████| 2000/2000 [00:31<00:00, 64.40it/s]\n",
      "epoch 015 avg_loss: 0.003 total_reward [train:22.000 test:16.000] e-greedy:0.027: 100%|██████████| 2000/2000 [00:30<00:00, 65.63it/s]\n",
      "epoch 016 each step reward:1.000:   1%|          | 15/2000 [00:00<00:24, 80.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 016 avg_loss: 0.004 total_reward [train:19.000 test:19.000] e-greedy:0.029: 100%|██████████| 2000/2000 [00:30<00:00, 65.76it/s]\n",
      "epoch 017 avg_loss: 0.003 total_reward [train:17.000 test:12.000] e-greedy:0.031: 100%|██████████| 2000/2000 [00:31<00:00, 64.44it/s]\n",
      "epoch 018 avg_loss: 0.003 total_reward [train:20.000 test:16.000] e-greedy:0.032: 100%|██████████| 2000/2000 [00:30<00:00, 65.69it/s]\n",
      "epoch 019 avg_loss: 0.003 total_reward [train:23.000 test:13.000] e-greedy:0.034: 100%|██████████| 2000/2000 [00:29<00:00, 66.80it/s]\n",
      "epoch 020 avg_loss: 0.003 total_reward [train:20.000 test:17.000] e-greedy:0.036: 100%|██████████| 2000/2000 [00:30<00:00, 65.41it/s]\n",
      "epoch 021 each step reward:0.000:   1%|          | 14/2000 [00:00<00:26, 73.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 19.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 021 avg_loss: 0.005 total_reward [train:26.000 test:11.000] e-greedy:0.038: 100%|██████████| 2000/2000 [00:31<00:00, 63.96it/s]\n",
      "epoch 022 avg_loss: 0.003 total_reward [train:19.000 test:14.000] e-greedy:0.040: 100%|██████████| 2000/2000 [00:30<00:00, 64.67it/s]\n",
      "epoch 023 avg_loss: 0.004 total_reward [train:21.000 test:2.000] e-greedy:0.041: 100%|██████████| 2000/2000 [00:31<00:00, 62.92it/s]\n",
      "epoch 024 avg_loss: 0.004 total_reward [train:23.000 test:8.000] e-greedy:0.043: 100%|██████████| 2000/2000 [00:30<00:00, 65.10it/s]\n",
      "epoch 025 avg_loss: 0.004 total_reward [train:26.000 test:16.000] e-greedy:0.045: 100%|██████████| 2000/2000 [00:31<00:00, 63.21it/s]\n",
      "epoch 026 each step reward:1.000:   1%|          | 16/2000 [00:00<00:25, 79.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 026 avg_loss: 0.005 total_reward [train:23.000 test:12.000] e-greedy:0.047: 100%|██████████| 2000/2000 [00:31<00:00, 65.92it/s]\n",
      "epoch 027 avg_loss: 0.004 total_reward [train:24.000 test:13.000] e-greedy:0.049: 100%|██████████| 2000/2000 [00:30<00:00, 64.81it/s]\n",
      "epoch 028 avg_loss: 0.004 total_reward [train:21.000 test:10.000] e-greedy:0.050: 100%|██████████| 2000/2000 [00:31<00:00, 62.94it/s]\n",
      "epoch 029 avg_loss: 0.004 total_reward [train:17.000 test:14.000] e-greedy:0.052: 100%|██████████| 2000/2000 [00:31<00:00, 62.72it/s]\n",
      "epoch 030 avg_loss: 0.004 total_reward [train:25.000 test:18.000] e-greedy:0.054: 100%|██████████| 2000/2000 [00:31<00:00, 64.36it/s]\n",
      "epoch 031 each step reward:1.000:   1%|          | 14/2000 [00:00<00:28, 70.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 18.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 031 avg_loss: 0.005 total_reward [train:18.000 test:15.000] e-greedy:0.056: 100%|██████████| 2000/2000 [00:31<00:00, 63.64it/s]\n",
      "epoch 032 avg_loss: 0.004 total_reward [train:25.000 test:14.000] e-greedy:0.058: 100%|██████████| 2000/2000 [00:31<00:00, 64.31it/s]\n",
      "epoch 033 avg_loss: 0.004 total_reward [train:26.000 test:11.000] e-greedy:0.059: 100%|██████████| 2000/2000 [00:31<00:00, 63.25it/s]\n",
      "epoch 034 avg_loss: 0.004 total_reward [train:20.000 test:10.000] e-greedy:0.061: 100%|██████████| 2000/2000 [00:31<00:00, 63.78it/s]\n",
      "epoch 035 avg_loss: 0.004 total_reward [train:17.000 test:3.000] e-greedy:0.063: 100%|██████████| 2000/2000 [00:31<00:00, 63.00it/s]\n",
      "epoch 036 each step reward:1.000:   1%|          | 14/2000 [00:00<00:26, 74.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 036 avg_loss: 0.005 total_reward [train:19.000 test:12.000] e-greedy:0.065: 100%|██████████| 2000/2000 [00:31<00:00, 63.43it/s]\n",
      "epoch 037 avg_loss: 0.004 total_reward [train:19.000 test:12.000] e-greedy:0.067: 100%|██████████| 2000/2000 [00:31<00:00, 63.59it/s]\n",
      "epoch 038 avg_loss: 0.005 total_reward [train:23.000 test:9.000] e-greedy:0.068: 100%|██████████| 2000/2000 [00:30<00:00, 71.26it/s]\n",
      "epoch 039 avg_loss: 0.004 total_reward [train:18.000 test:16.000] e-greedy:0.070: 100%|██████████| 2000/2000 [00:31<00:00, 63.57it/s]\n",
      "epoch 040 avg_loss: 0.004 total_reward [train:19.000 test:5.000] e-greedy:0.072: 100%|██████████| 2000/2000 [00:31<00:00, 63.04it/s]\n",
      "epoch 041 each step reward:0.000:   1%|          | 14/2000 [00:00<00:26, 73.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 041 avg_loss: 0.005 total_reward [train:23.000 test:9.000] e-greedy:0.074: 100%|██████████| 2000/2000 [00:31<00:00, 63.73it/s]\n",
      "epoch 042 avg_loss: 0.004 total_reward [train:25.000 test:10.000] e-greedy:0.076: 100%|██████████| 2000/2000 [00:31<00:00, 63.87it/s]\n",
      "epoch 043 avg_loss: 0.004 total_reward [train:26.000 test:7.000] e-greedy:0.077: 100%|██████████| 2000/2000 [00:31<00:00,  6.74it/s]\n",
      "epoch 044 avg_loss: 0.004 total_reward [train:17.000 test:12.000] e-greedy:0.079: 100%|██████████| 2000/2000 [00:32<00:00, 62.49it/s]\n",
      "epoch 045 avg_loss: 0.004 total_reward [train:17.000 test:14.000] e-greedy:0.081: 100%|██████████| 2000/2000 [00:31<00:00, 63.26it/s]\n",
      "epoch 046 each step reward:0.000:   1%|          | 12/2000 [00:00<00:27, 71.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 14.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 046 avg_loss: 0.006 total_reward [train:18.000 test:14.000] e-greedy:0.083: 100%|██████████| 2000/2000 [00:31<00:00, 67.71it/s]\n",
      "epoch 047 avg_loss: 0.005 total_reward [train:19.000 test:8.000] e-greedy:0.085: 100%|██████████| 2000/2000 [00:31<00:00, 63.14it/s]\n",
      "epoch 048 avg_loss: 0.005 total_reward [train:20.000 test:15.000] e-greedy:0.086: 100%|██████████| 2000/2000 [00:31<00:00, 63.85it/s]\n",
      "epoch 049 avg_loss: 0.005 total_reward [train:24.000 test:12.000] e-greedy:0.088: 100%|██████████| 2000/2000 [00:31<00:00, 63.59it/s]\n",
      "epoch 050 avg_loss: 0.005 total_reward [train:23.000 test:13.000] e-greedy:0.090: 100%|██████████| 2000/2000 [00:31<00:00, 62.92it/s]\n",
      "epoch 051 each step reward:0.000:   1%|          | 11/2000 [00:00<00:31, 63.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 051 avg_loss: 0.006 total_reward [train:22.000 test:15.000] e-greedy:0.092: 100%|██████████| 2000/2000 [00:31<00:00,  6.42it/s]\n",
      "epoch 052 avg_loss: 0.005 total_reward [train:16.000 test:9.000] e-greedy:0.094: 100%|██████████| 2000/2000 [00:32<00:00, 62.14it/s]\n",
      "epoch 053 avg_loss: 0.005 total_reward [train:21.000 test:10.000] e-greedy:0.095: 100%|██████████| 2000/2000 [00:31<00:00, 65.46it/s]\n",
      "epoch 054 avg_loss: 0.005 total_reward [train:24.000 test:13.000] e-greedy:0.097: 100%|██████████| 2000/2000 [00:31<00:00, 63.95it/s]\n",
      "epoch 055 avg_loss: 0.005 total_reward [train:19.000 test:15.000] e-greedy:0.099: 100%|██████████| 2000/2000 [00:31<00:00, 64.04it/s]\n",
      "epoch 056 each step reward:0.000:   1%|          | 14/2000 [00:00<00:27, 72.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 056 avg_loss: 0.006 total_reward [train:20.000 test:4.000] e-greedy:0.101: 100%|██████████| 2000/2000 [00:31<00:00, 63.05it/s]\n",
      "epoch 057 avg_loss: 0.006 total_reward [train:24.000 test:12.000] e-greedy:0.103: 100%|██████████| 2000/2000 [00:31<00:00, 64.04it/s]\n",
      "epoch 058 avg_loss: 0.005 total_reward [train:25.000 test:15.000] e-greedy:0.104: 100%|██████████| 2000/2000 [00:31<00:00, 63.47it/s]\n",
      "epoch 059 avg_loss: 0.005 total_reward [train:23.000 test:6.000] e-greedy:0.106: 100%|██████████| 2000/2000 [00:31<00:00, 63.64it/s]\n",
      "epoch 060 avg_loss: 0.005 total_reward [train:20.000 test:13.000] e-greedy:0.108: 100%|██████████| 2000/2000 [00:31<00:00, 64.19it/s]\n",
      "epoch 061 each step reward:0.000:   1%|          | 14/2000 [00:00<00:28, 70.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 061 avg_loss: 0.007 total_reward [train:17.000 test:14.000] e-greedy:0.110: 100%|██████████| 2000/2000 [00:31<00:00, 63.33it/s]\n",
      "epoch 062 avg_loss: 0.006 total_reward [train:24.000 test:16.000] e-greedy:0.112: 100%|██████████| 2000/2000 [00:31<00:00, 64.40it/s]\n",
      "epoch 063 avg_loss: 0.006 total_reward [train:22.000 test:12.000] e-greedy:0.113: 100%|██████████| 2000/2000 [00:31<00:00, 63.93it/s]\n",
      "epoch 064 avg_loss: 0.006 total_reward [train:25.000 test:15.000] e-greedy:0.115: 100%|██████████| 2000/2000 [00:30<00:00, 66.37it/s]\n",
      "epoch 065 avg_loss: 0.005 total_reward [train:27.000 test:12.000] e-greedy:0.117: 100%|██████████| 2000/2000 [00:30<00:00, 65.21it/s]\n",
      "epoch 066 each step reward:0.000:   1%|          | 16/2000 [00:00<00:25, 76.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 066 avg_loss: 0.007 total_reward [train:26.000 test:16.000] e-greedy:0.119: 100%|██████████| 2000/2000 [00:30<00:00, 64.70it/s]\n",
      "epoch 067 avg_loss: 0.005 total_reward [train:25.000 test:15.000] e-greedy:0.121: 100%|██████████| 2000/2000 [00:31<00:00, 64.80it/s]\n",
      "epoch 068 avg_loss: 0.005 total_reward [train:22.000 test:14.000] e-greedy:0.122: 100%|██████████| 2000/2000 [00:31<00:00, 63.55it/s]\n",
      "epoch 069 avg_loss: 0.006 total_reward [train:25.000 test:15.000] e-greedy:0.124: 100%|██████████| 2000/2000 [00:31<00:00, 63.99it/s]\n",
      "epoch 070 avg_loss: 0.005 total_reward [train:27.000 test:10.000] e-greedy:0.126: 100%|██████████| 2000/2000 [00:32<00:00, 61.49it/s]\n",
      "epoch 071 each step reward:0.000:   1%|          | 11/2000 [00:00<00:31, 62.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 071 avg_loss: 0.006 total_reward [train:23.000 test:17.000] e-greedy:0.128: 100%|██████████| 2000/2000 [00:31<00:00, 63.44it/s]\n",
      "epoch 072 avg_loss: 0.006 total_reward [train:26.000 test:13.000] e-greedy:0.130: 100%|██████████| 2000/2000 [00:30<00:00, 64.90it/s]\n",
      "epoch 073 avg_loss: 0.006 total_reward [train:25.000 test:13.000] e-greedy:0.131: 100%|██████████| 2000/2000 [00:32<00:00, 61.71it/s]\n",
      "epoch 074 avg_loss: 0.006 total_reward [train:23.000 test:15.000] e-greedy:0.133: 100%|██████████| 2000/2000 [00:32<00:00, 61.82it/s]\n",
      "epoch 075 avg_loss: 0.006 total_reward [train:17.000 test:18.000] e-greedy:0.135: 100%|██████████| 2000/2000 [00:31<00:00, 63.23it/s]\n",
      "epoch 076 each step reward:0.000:   1%|          | 13/2000 [00:00<00:32, 61.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 18.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 076 avg_loss: 0.007 total_reward [train:23.000 test:14.000] e-greedy:0.137: 100%|██████████| 2000/2000 [00:31<00:00, 63.38it/s]\n",
      "epoch 077 avg_loss: 0.006 total_reward [train:28.000 test:14.000] e-greedy:0.139: 100%|██████████| 2000/2000 [00:32<00:00, 62.49it/s]\n",
      "epoch 078 avg_loss: 0.006 total_reward [train:27.000 test:15.000] e-greedy:0.140: 100%|██████████| 2000/2000 [00:31<00:00, 62.96it/s]\n",
      "epoch 079 avg_loss: 0.006 total_reward [train:28.000 test:16.000] e-greedy:0.142: 100%|██████████| 2000/2000 [00:31<00:00, 63.56it/s]\n",
      "epoch 080 avg_loss: 0.006 total_reward [train:24.000 test:18.000] e-greedy:0.144: 100%|██████████| 2000/2000 [00:31<00:00, 64.29it/s]\n",
      "epoch 081 each step reward:0.000:   0%|          | 10/2000 [00:00<00:33, 60.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 18.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 081 avg_loss: 0.007 total_reward [train:26.000 test:14.000] e-greedy:0.146: 100%|██████████| 2000/2000 [00:31<00:00, 63.28it/s]\n",
      "epoch 082 avg_loss: 0.007 total_reward [train:21.000 test:16.000] e-greedy:0.148: 100%|██████████| 2000/2000 [00:32<00:00, 61.74it/s]\n",
      "epoch 083 avg_loss: 0.007 total_reward [train:24.000 test:18.000] e-greedy:0.149: 100%|██████████| 2000/2000 [00:30<00:00, 65.74it/s]\n",
      "epoch 084 avg_loss: 0.006 total_reward [train:24.000 test:15.000] e-greedy:0.151: 100%|██████████| 2000/2000 [00:30<00:00, 66.19it/s]\n",
      "epoch 085 avg_loss: 0.006 total_reward [train:29.000 test:14.000] e-greedy:0.153: 100%|██████████| 2000/2000 [00:29<00:00, 79.54it/s]\n",
      "epoch 086 each step reward:0.000:   1%|          | 14/2000 [00:00<00:25, 77.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 18.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 086 avg_loss: 0.008 total_reward [train:23.000 test:18.000] e-greedy:0.155: 100%|██████████| 2000/2000 [00:29<00:00, 67.15it/s]\n",
      "epoch 087 avg_loss: 0.007 total_reward [train:22.000 test:17.000] e-greedy:0.157: 100%|██████████| 2000/2000 [00:29<00:00, 66.87it/s]\n",
      "epoch 088 avg_loss: 0.007 total_reward [train:28.000 test:18.000] e-greedy:0.158: 100%|██████████| 2000/2000 [00:29<00:00, 67.36it/s]\n",
      "epoch 089 avg_loss: 0.006 total_reward [train:24.000 test:18.000] e-greedy:0.160: 100%|██████████| 2000/2000 [00:29<00:00, 67.29it/s]\n",
      "epoch 090 avg_loss: 0.007 total_reward [train:25.000 test:14.000] e-greedy:0.162: 100%|██████████| 2000/2000 [00:30<00:00, 70.86it/s]\n",
      "epoch 091 each step reward:0.000:   1%|          | 16/2000 [00:00<00:24, 80.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 18.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 091 avg_loss: 0.008 total_reward [train:21.000 test:13.000] e-greedy:0.164: 100%|██████████| 2000/2000 [00:29<00:00, 66.94it/s]\n",
      "epoch 092 avg_loss: 0.007 total_reward [train:20.000 test:14.000] e-greedy:0.166: 100%|██████████| 2000/2000 [00:30<00:00, 66.39it/s]\n",
      "epoch 093 avg_loss: 0.007 total_reward [train:29.000 test:8.000] e-greedy:0.167: 100%|██████████| 2000/2000 [00:30<00:00, 66.60it/s]\n",
      "epoch 094 avg_loss: 0.007 total_reward [train:29.000 test:18.000] e-greedy:0.169: 100%|██████████| 2000/2000 [00:29<00:00, 66.72it/s]\n",
      "epoch 095 avg_loss: 0.007 total_reward [train:31.000 test:18.000] e-greedy:0.171: 100%|██████████| 2000/2000 [00:29<00:00, 66.74it/s]\n",
      "epoch 096 each step reward:0.000:   1%|          | 17/2000 [00:00<00:24, 80.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 18.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 096 avg_loss: 0.008 total_reward [train:28.000 test:11.000] e-greedy:0.173: 100%|██████████| 2000/2000 [00:29<00:00, 76.16it/s]\n",
      "epoch 097 avg_loss: 0.008 total_reward [train:24.000 test:14.000] e-greedy:0.175: 100%|██████████| 2000/2000 [00:29<00:00, 67.10it/s]\n",
      "epoch 098 avg_loss: 0.008 total_reward [train:29.000 test:18.000] e-greedy:0.176: 100%|██████████| 2000/2000 [00:29<00:00, 67.81it/s]\n",
      "epoch 099 avg_loss: 0.007 total_reward [train:27.000 test:16.000] e-greedy:0.178: 100%|██████████| 2000/2000 [00:29<00:00, 67.05it/s]\n",
      "epoch 100 avg_loss: 0.007 total_reward [train:24.000 test:14.000] e-greedy:0.180: 100%|██████████| 2000/2000 [00:29<00:00, 66.96it/s]\n",
      "epoch 101 each step reward:0.000:   1%|          | 15/2000 [00:00<00:24, 81.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 18.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 101 avg_loss: 0.008 total_reward [train:24.000 test:17.000] e-greedy:0.182: 100%|██████████| 2000/2000 [00:30<00:00, 66.04it/s]\n",
      "epoch 102 avg_loss: 0.008 total_reward [train:22.000 test:21.000] e-greedy:0.184: 100%|██████████| 2000/2000 [00:29<00:00, 66.97it/s]\n",
      "epoch 103 avg_loss: 0.008 total_reward [train:25.000 test:17.000] e-greedy:0.185: 100%|██████████| 2000/2000 [00:29<00:00, 66.93it/s]\n",
      "epoch 104 avg_loss: 0.007 total_reward [train:28.000 test:16.000] e-greedy:0.187: 100%|██████████| 2000/2000 [00:30<00:00, 66.48it/s]\n",
      "epoch 105 avg_loss: 0.007 total_reward [train:25.000 test:16.000] e-greedy:0.189: 100%|██████████| 2000/2000 [00:29<00:00, 67.41it/s]\n",
      "epoch 106 each step reward:0.000:   1%|          | 13/2000 [00:00<00:32, 61.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 106 avg_loss: 0.009 total_reward [train:29.000 test:20.000] e-greedy:0.191: 100%|██████████| 2000/2000 [00:29<00:00, 67.53it/s]\n",
      "epoch 107 avg_loss: 0.009 total_reward [train:30.000 test:17.000] e-greedy:0.193: 100%|██████████| 2000/2000 [00:29<00:00, 67.45it/s]\n",
      "epoch 108 avg_loss: 0.008 total_reward [train:22.000 test:21.000] e-greedy:0.194: 100%|██████████| 2000/2000 [00:29<00:00, 67.64it/s]\n",
      "epoch 109 avg_loss: 0.008 total_reward [train:28.000 test:20.000] e-greedy:0.196: 100%|██████████| 2000/2000 [00:29<00:00, 73.02it/s]\n",
      "epoch 110 avg_loss: 0.008 total_reward [train:28.000 test:19.000] e-greedy:0.198: 100%|██████████| 2000/2000 [00:29<00:00, 67.50it/s]\n",
      "epoch 111 each step reward:0.000:   1%|          | 15/2000 [00:00<00:26, 73.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 111 avg_loss: 0.010 total_reward [train:28.000 test:15.000] e-greedy:0.200: 100%|██████████| 2000/2000 [00:29<00:00, 67.37it/s]\n",
      "epoch 112 avg_loss: 0.010 total_reward [train:29.000 test:24.000] e-greedy:0.202: 100%|██████████| 2000/2000 [00:29<00:00, 67.81it/s]\n",
      "epoch 113 avg_loss: 0.009 total_reward [train:27.000 test:13.000] e-greedy:0.203: 100%|██████████| 2000/2000 [00:29<00:00, 66.85it/s]\n",
      "epoch 114 avg_loss: 0.009 total_reward [train:26.000 test:19.000] e-greedy:0.205: 100%|██████████| 2000/2000 [00:29<00:00, 67.02it/s]\n",
      "epoch 115 avg_loss: 0.009 total_reward [train:23.000 test:21.000] e-greedy:0.207: 100%|██████████| 2000/2000 [00:29<00:00, 67.55it/s]\n",
      "epoch 116 each step reward:0.000:   1%|          | 16/2000 [00:00<00:25, 78.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 24.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 116 avg_loss: 0.011 total_reward [train:26.000 test:18.000] e-greedy:0.209: 100%|██████████| 2000/2000 [00:29<00:00, 66.72it/s]\n",
      "epoch 117 avg_loss: 0.010 total_reward [train:26.000 test:15.000] e-greedy:0.211: 100%|██████████| 2000/2000 [00:29<00:00, 67.18it/s]\n",
      "epoch 118 avg_loss: 0.010 total_reward [train:33.000 test:24.000] e-greedy:0.212: 100%|██████████| 2000/2000 [00:28<00:00, 69.36it/s]\n",
      "epoch 119 avg_loss: 0.010 total_reward [train:26.000 test:19.000] e-greedy:0.214: 100%|██████████| 2000/2000 [00:29<00:00, 67.47it/s]\n",
      "epoch 120 avg_loss: 0.010 total_reward [train:33.000 test:16.000] e-greedy:0.216: 100%|██████████| 2000/2000 [00:29<00:00, 67.35it/s]\n",
      "epoch 121 each step reward:1.000:   1%|          | 16/2000 [00:00<00:25, 79.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 24.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 121 avg_loss: 0.012 total_reward [train:28.000 test:15.000] e-greedy:0.218: 100%|██████████| 2000/2000 [00:29<00:00, 67.72it/s]\n",
      "epoch 122 avg_loss: 0.011 total_reward [train:26.000 test:20.000] e-greedy:0.220: 100%|██████████| 2000/2000 [00:29<00:00, 67.23it/s]\n",
      "epoch 123 avg_loss: 0.011 total_reward [train:28.000 test:21.000] e-greedy:0.221: 100%|██████████| 2000/2000 [00:29<00:00, 67.83it/s]\n",
      "epoch 124 avg_loss: 0.011 total_reward [train:29.000 test:19.000] e-greedy:0.223: 100%|██████████| 2000/2000 [00:29<00:00, 66.85it/s]\n",
      "epoch 125 avg_loss: 0.010 total_reward [train:30.000 test:19.000] e-greedy:0.225: 100%|██████████| 2000/2000 [00:29<00:00, 67.94it/s]\n",
      "epoch 126 each step reward:1.000:   1%|          | 16/2000 [00:00<00:25, 78.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 126 avg_loss: 0.013 total_reward [train:34.000 test:20.000] e-greedy:0.227: 100%|██████████| 2000/2000 [00:29<00:00, 68.42it/s]\n",
      "epoch 127 avg_loss: 0.013 total_reward [train:30.000 test:15.000] e-greedy:0.229: 100%|██████████| 2000/2000 [00:29<00:00, 67.90it/s]\n",
      "epoch 128 avg_loss: 0.012 total_reward [train:27.000 test:22.000] e-greedy:0.230: 100%|██████████| 2000/2000 [00:29<00:00, 67.09it/s]\n",
      "epoch 129 avg_loss: 0.011 total_reward [train:26.000 test:23.000] e-greedy:0.232: 100%|██████████| 2000/2000 [00:29<00:00, 68.01it/s]\n",
      "epoch 130 avg_loss: 0.012 total_reward [train:30.000 test:21.000] e-greedy:0.234: 100%|██████████| 2000/2000 [00:29<00:00, 68.12it/s]\n",
      "epoch 131 each step reward:1.000:   1%|          | 12/2000 [00:00<00:36, 54.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 23.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 131 avg_loss: 0.015 total_reward [train:26.000 test:21.000] e-greedy:0.236: 100%|██████████| 2000/2000 [00:29<00:00, 66.94it/s]\n",
      "epoch 132 avg_loss: 0.014 total_reward [train:33.000 test:20.000] e-greedy:0.238: 100%|██████████| 2000/2000 [00:29<00:00, 67.87it/s]\n",
      "epoch 133 avg_loss: 0.013 total_reward [train:28.000 test:18.000] e-greedy:0.239: 100%|██████████| 2000/2000 [00:29<00:00, 68.18it/s]\n",
      "epoch 134 avg_loss: 0.013 total_reward [train:29.000 test:21.000] e-greedy:0.241: 100%|██████████| 2000/2000 [00:29<00:00, 68.61it/s]\n",
      "epoch 135 avg_loss: 0.013 total_reward [train:22.000 test:21.000] e-greedy:0.243: 100%|██████████| 2000/2000 [00:29<00:00, 73.22it/s]\n",
      "epoch 136 each step reward:0.000:   1%|          | 13/2000 [00:00<00:36, 54.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 136 avg_loss: 0.016 total_reward [train:36.000 test:19.000] e-greedy:0.245: 100%|██████████| 2000/2000 [00:29<00:00, 68.08it/s]\n",
      "epoch 137 avg_loss: 0.015 total_reward [train:24.000 test:21.000] e-greedy:0.247: 100%|██████████| 2000/2000 [00:29<00:00, 67.21it/s]\n",
      "epoch 138 avg_loss: 0.015 total_reward [train:31.000 test:15.000] e-greedy:0.248: 100%|██████████| 2000/2000 [00:29<00:00, 69.89it/s]\n",
      "epoch 139 avg_loss: 0.015 total_reward [train:32.000 test:21.000] e-greedy:0.250: 100%|██████████| 2000/2000 [00:29<00:00, 68.24it/s]\n",
      "epoch 140 avg_loss: 0.014 total_reward [train:28.000 test:19.000] e-greedy:0.252: 100%|██████████| 2000/2000 [00:29<00:00, 67.23it/s]\n",
      "epoch 141 each step reward:0.000:   1%|          | 16/2000 [00:00<00:25, 78.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 141 avg_loss: 0.018 total_reward [train:29.000 test:22.000] e-greedy:0.254: 100%|██████████| 2000/2000 [00:29<00:00, 67.96it/s]\n",
      "epoch 142 avg_loss: 0.017 total_reward [train:25.000 test:19.000] e-greedy:0.256: 100%|██████████| 2000/2000 [00:29<00:00, 67.17it/s]\n",
      "epoch 143 avg_loss: 0.018 total_reward [train:29.000 test:19.000] e-greedy:0.257: 100%|██████████| 2000/2000 [00:29<00:00, 67.28it/s]\n",
      "epoch 144 avg_loss: 0.017 total_reward [train:38.000 test:15.000] e-greedy:0.259: 100%|██████████| 2000/2000 [00:29<00:00, 68.45it/s]\n",
      "epoch 145 avg_loss: 0.017 total_reward [train:26.000 test:19.000] e-greedy:0.261: 100%|██████████| 2000/2000 [00:29<00:00, 67.97it/s]\n",
      "epoch 146 each step reward:1.000:   1%|          | 16/2000 [00:00<00:24, 79.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 22.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 146 avg_loss: 0.018 total_reward [train:26.000 test:21.000] e-greedy:0.263: 100%|██████████| 2000/2000 [00:29<00:00, 67.33it/s]\n",
      "epoch 147 avg_loss: 0.018 total_reward [train:28.000 test:21.000] e-greedy:0.265: 100%|██████████| 2000/2000 [00:29<00:00, 76.52it/s]\n",
      "epoch 148 avg_loss: 0.018 total_reward [train:22.000 test:20.000] e-greedy:0.266: 100%|██████████| 2000/2000 [00:30<00:00, 66.59it/s]\n",
      "epoch 149 avg_loss: 0.018 total_reward [train:30.000 test:22.000] e-greedy:0.268: 100%|██████████| 2000/2000 [00:30<00:00, 65.48it/s]\n",
      "epoch 150 avg_loss: 0.018 total_reward [train:28.000 test:22.000] e-greedy:0.270: 100%|██████████| 2000/2000 [00:31<00:00, 64.51it/s]\n",
      "epoch 151 each step reward:0.000:   1%|          | 14/2000 [00:00<00:27, 71.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 22.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 151 avg_loss: 0.021 total_reward [train:24.000 test:18.000] e-greedy:0.272: 100%|██████████| 2000/2000 [00:30<00:00, 64.67it/s]\n",
      "epoch 152 avg_loss: 0.020 total_reward [train:34.000 test:20.000] e-greedy:0.274: 100%|██████████| 2000/2000 [00:31<00:00, 63.82it/s]\n",
      "epoch 153 avg_loss: 0.020 total_reward [train:23.000 test:23.000] e-greedy:0.275: 100%|██████████| 2000/2000 [00:31<00:00, 64.11it/s]\n",
      "epoch 154 avg_loss: 0.019 total_reward [train:28.000 test:20.000] e-greedy:0.277: 100%|██████████| 2000/2000 [00:31<00:00, 64.29it/s]\n",
      "epoch 155 avg_loss: 0.019 total_reward [train:29.000 test:19.000] e-greedy:0.279: 100%|██████████| 2000/2000 [00:31<00:00, 64.22it/s]\n",
      "epoch 156 each step reward:0.000:   1%|          | 13/2000 [00:00<00:28, 69.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 23.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 156 avg_loss: 0.023 total_reward [train:31.000 test:23.000] e-greedy:0.281: 100%|██████████| 2000/2000 [00:29<00:00, 71.96it/s]\n",
      "epoch 157 avg_loss: 0.022 total_reward [train:26.000 test:21.000] e-greedy:0.283: 100%|██████████| 2000/2000 [00:30<00:00, 64.92it/s]\n",
      "epoch 158 avg_loss: 0.022 total_reward [train:24.000 test:20.000] e-greedy:0.284: 100%|██████████| 2000/2000 [00:31<00:00, 63.61it/s]\n",
      "epoch 159 avg_loss: 0.021 total_reward [train:31.000 test:12.000] e-greedy:0.286: 100%|██████████| 2000/2000 [00:30<00:00, 65.69it/s]\n",
      "epoch 160 avg_loss: 0.021 total_reward [train:24.000 test:21.000] e-greedy:0.288: 100%|██████████| 2000/2000 [00:31<00:00, 63.87it/s]\n",
      "epoch 161 each step reward:0.000:   1%|          | 12/2000 [00:00<00:36, 53.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 23.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 161 avg_loss: 0.024 total_reward [train:33.000 test:23.000] e-greedy:0.290: 100%|██████████| 2000/2000 [00:30<00:00, 65.48it/s]\n",
      "epoch 162 avg_loss: 0.023 total_reward [train:31.000 test:21.000] e-greedy:0.292: 100%|██████████| 2000/2000 [00:30<00:00, 65.39it/s]\n",
      "epoch 163 avg_loss: 0.023 total_reward [train:27.000 test:22.000] e-greedy:0.293: 100%|██████████| 2000/2000 [00:30<00:00, 68.29it/s]\n",
      "epoch 164 avg_loss: 0.022 total_reward [train:35.000 test:21.000] e-greedy:0.295: 100%|██████████| 2000/2000 [00:30<00:00, 65.66it/s]\n",
      "epoch 165 avg_loss: 0.023 total_reward [train:24.000 test:22.000] e-greedy:0.297: 100%|██████████| 2000/2000 [00:30<00:00,  8.48it/s]\n",
      "epoch 166 each step reward:0.000:   1%|          | 14/2000 [00:00<00:29, 66.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 23.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 166 avg_loss: 0.025 total_reward [train:23.000 test:19.000] e-greedy:0.299: 100%|██████████| 2000/2000 [00:30<00:00, 64.79it/s]\n",
      "epoch 167 avg_loss: 0.024 total_reward [train:25.000 test:22.000] e-greedy:0.301: 100%|██████████| 2000/2000 [00:30<00:00, 65.09it/s]\n",
      "epoch 168 avg_loss: 0.024 total_reward [train:26.000 test:19.000] e-greedy:0.302: 100%|██████████| 2000/2000 [00:31<00:00, 63.94it/s]\n",
      "epoch 169 avg_loss: 0.023 total_reward [train:31.000 test:21.000] e-greedy:0.304: 100%|██████████| 2000/2000 [00:32<00:00, 61.93it/s]\n",
      "epoch 170 avg_loss: 0.023 total_reward [train:31.000 test:16.000] e-greedy:0.306: 100%|██████████| 2000/2000 [00:30<00:00, 65.08it/s]\n",
      "epoch 171 each step reward:0.000:   1%|          | 13/2000 [00:00<00:29, 68.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 22.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 171 avg_loss: 0.025 total_reward [train:24.000 test:25.000] e-greedy:0.308: 100%|██████████| 2000/2000 [00:31<00:00, 64.24it/s]\n",
      "epoch 172 avg_loss: 0.025 total_reward [train:24.000 test:23.000] e-greedy:0.310: 100%|██████████| 2000/2000 [00:30<00:00, 65.03it/s]\n",
      "epoch 173 avg_loss: 0.025 total_reward [train:24.000 test:24.000] e-greedy:0.311: 100%|██████████| 2000/2000 [00:30<00:00, 65.06it/s]\n",
      "epoch 174 avg_loss: 0.025 total_reward [train:31.000 test:23.000] e-greedy:0.313: 100%|██████████| 2000/2000 [00:30<00:00, 65.66it/s]\n",
      "epoch 175 avg_loss: 0.024 total_reward [train:22.000 test:20.000] e-greedy:0.315: 100%|██████████| 2000/2000 [00:31<00:00, 63.75it/s]\n",
      "epoch 176 each step reward:0.000:   1%|          | 15/2000 [00:00<00:28, 70.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 25.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 176 avg_loss: 0.027 total_reward [train:31.000 test:20.000] e-greedy:0.317: 100%|██████████| 2000/2000 [00:32<00:00, 61.84it/s]\n",
      "epoch 177 avg_loss: 0.026 total_reward [train:28.000 test:21.000] e-greedy:0.319: 100%|██████████| 2000/2000 [00:31<00:00, 64.27it/s]\n",
      "epoch 178 avg_loss: 0.026 total_reward [train:25.000 test:20.000] e-greedy:0.320: 100%|██████████| 2000/2000 [00:32<00:00, 61.71it/s]\n",
      "epoch 179 avg_loss: 0.026 total_reward [train:32.000 test:18.000] e-greedy:0.322: 100%|██████████| 2000/2000 [00:30<00:00, 64.55it/s]\n",
      "epoch 180 avg_loss: 0.026 total_reward [train:29.000 test:18.000] e-greedy:0.324: 100%|██████████| 2000/2000 [00:31<00:00, 63.90it/s]\n",
      "epoch 181 each step reward:0.000:   1%|          | 14/2000 [00:00<00:30, 64.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 181 avg_loss: 0.028 total_reward [train:31.000 test:20.000] e-greedy:0.326: 100%|██████████| 2000/2000 [00:31<00:00, 64.13it/s]\n",
      "epoch 182 avg_loss: 0.027 total_reward [train:32.000 test:20.000] e-greedy:0.328: 100%|██████████| 2000/2000 [00:31<00:00, 64.23it/s]\n",
      "epoch 183 avg_loss: 0.027 total_reward [train:32.000 test:21.000] e-greedy:0.329: 100%|██████████| 2000/2000 [00:30<00:00, 64.62it/s]\n",
      "epoch 184 avg_loss: 0.027 total_reward [train:25.000 test:21.000] e-greedy:0.331: 100%|██████████| 2000/2000 [00:30<00:00, 69.23it/s]\n",
      "epoch 185 avg_loss: 0.027 total_reward [train:26.000 test:21.000] e-greedy:0.333: 100%|██████████| 2000/2000 [00:30<00:00, 64.81it/s]\n",
      "epoch 186 each step reward:0.000:   1%|          | 13/2000 [00:00<00:27, 73.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 186 avg_loss: 0.029 total_reward [train:33.000 test:21.000] e-greedy:0.335: 100%|██████████| 2000/2000 [00:30<00:00, 64.95it/s]\n",
      "epoch 187 avg_loss: 0.029 total_reward [train:33.000 test:18.000] e-greedy:0.337: 100%|██████████| 2000/2000 [00:30<00:00, 64.91it/s]\n",
      "epoch 188 avg_loss: 0.029 total_reward [train:22.000 test:21.000] e-greedy:0.338: 100%|██████████| 2000/2000 [00:31<00:00, 63.12it/s]\n",
      "epoch 189 avg_loss: 0.029 total_reward [train:30.000 test:20.000] e-greedy:0.340: 100%|██████████| 2000/2000 [00:31<00:00, 72.18it/s]\n",
      "epoch 190 avg_loss: 0.028 total_reward [train:34.000 test:19.000] e-greedy:0.342: 100%|██████████| 2000/2000 [00:31<00:00, 63.33it/s]\n",
      "epoch 191 each step reward:0.000:   1%|          | 13/2000 [00:00<00:31, 64.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 191 avg_loss: 0.030 total_reward [train:25.000 test:20.000] e-greedy:0.344: 100%|██████████| 2000/2000 [00:31<00:00, 72.13it/s]\n",
      "epoch 192 avg_loss: 0.029 total_reward [train:27.000 test:23.000] e-greedy:0.346: 100%|██████████| 2000/2000 [00:31<00:00, 72.70it/s]\n",
      "epoch 193 avg_loss: 0.028 total_reward [train:28.000 test:22.000] e-greedy:0.347: 100%|██████████| 2000/2000 [00:31<00:00, 62.92it/s]\n",
      "epoch 194 avg_loss: 0.027 total_reward [train:30.000 test:20.000] e-greedy:0.349: 100%|██████████| 2000/2000 [00:31<00:00, 63.86it/s]\n",
      "epoch 195 avg_loss: 0.029 total_reward [train:28.000 test:23.000] e-greedy:0.351: 100%|██████████| 2000/2000 [00:32<00:00, 69.52it/s]\n",
      "epoch 196 each step reward:0.000:   1%|          | 13/2000 [00:00<00:25, 77.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 23.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 196 avg_loss: 0.031 total_reward [train:24.000 test:21.000] e-greedy:0.353: 100%|██████████| 2000/2000 [00:31<00:00, 63.08it/s]\n",
      "epoch 197 avg_loss: 0.029 total_reward [train:27.000 test:21.000] e-greedy:0.355: 100%|██████████| 2000/2000 [00:31<00:00,  8.54it/s]\n",
      "epoch 198 avg_loss: 0.030 total_reward [train:30.000 test:22.000] e-greedy:0.356: 100%|██████████| 2000/2000 [00:31<00:00, 63.83it/s]\n",
      "epoch 199 avg_loss: 0.029 total_reward [train:30.000 test:19.000] e-greedy:0.358: 100%|██████████| 2000/2000 [00:31<00:00, 71.35it/s]\n",
      "epoch 200 avg_loss: 0.029 total_reward [train:24.000 test:19.000] e-greedy:0.360: 100%|██████████| 2000/2000 [00:31<00:00, 63.63it/s]\n",
      "epoch 201 each step reward:0.000:   1%|          | 12/2000 [00:00<00:32, 60.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 22.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 201 avg_loss: 0.033 total_reward [train:28.000 test:20.000] e-greedy:0.362: 100%|██████████| 2000/2000 [00:31<00:00, 64.35it/s]\n",
      "epoch 202 avg_loss: 0.033 total_reward [train:31.000 test:20.000] e-greedy:0.364: 100%|██████████| 2000/2000 [00:31<00:00, 63.75it/s]\n",
      "epoch 203 avg_loss: 0.032 total_reward [train:28.000 test:20.000] e-greedy:0.365: 100%|██████████| 2000/2000 [00:31<00:00, 63.66it/s]\n",
      "epoch 204 avg_loss: 0.032 total_reward [train:29.000 test:21.000] e-greedy:0.367: 100%|██████████| 2000/2000 [00:32<00:00, 62.01it/s]\n",
      "epoch 205 avg_loss: 0.032 total_reward [train:28.000 test:16.000] e-greedy:0.369: 100%|██████████| 2000/2000 [00:31<00:00, 64.01it/s]\n",
      "epoch 206 each step reward:0.000:   1%|          | 14/2000 [00:00<00:25, 76.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 206 avg_loss: 0.032 total_reward [train:33.000 test:21.000] e-greedy:0.371: 100%|██████████| 2000/2000 [00:30<00:00, 64.65it/s]\n",
      "epoch 207 avg_loss: 0.031 total_reward [train:33.000 test:19.000] e-greedy:0.373: 100%|██████████| 2000/2000 [00:31<00:00, 63.23it/s]\n",
      "epoch 208 avg_loss: 0.031 total_reward [train:34.000 test:19.000] e-greedy:0.374: 100%|██████████| 2000/2000 [00:30<00:00, 64.69it/s]\n",
      "epoch 209 avg_loss: 0.031 total_reward [train:29.000 test:19.000] e-greedy:0.376: 100%|██████████| 2000/2000 [00:30<00:00, 64.65it/s]\n",
      "epoch 210 avg_loss: 0.031 total_reward [train:33.000 test:14.000] e-greedy:0.378: 100%|██████████| 2000/2000 [00:30<00:00, 65.13it/s]\n",
      "epoch 211 each step reward:0.000:   1%|          | 15/2000 [00:00<00:28, 70.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 211 avg_loss: 0.033 total_reward [train:32.000 test:21.000] e-greedy:0.380: 100%|██████████| 2000/2000 [00:30<00:00, 64.70it/s]\n",
      "epoch 212 avg_loss: 0.034 total_reward [train:28.000 test:19.000] e-greedy:0.382: 100%|██████████| 2000/2000 [00:31<00:00, 63.78it/s]\n",
      "epoch 213 avg_loss: 0.033 total_reward [train:29.000 test:20.000] e-greedy:0.383: 100%|██████████| 2000/2000 [00:30<00:00, 64.62it/s]\n",
      "epoch 214 avg_loss: 0.033 total_reward [train:31.000 test:20.000] e-greedy:0.385: 100%|██████████| 2000/2000 [00:31<00:00, 63.48it/s]\n",
      "epoch 215 avg_loss: 0.032 total_reward [train:29.000 test:22.000] e-greedy:0.387: 100%|██████████| 2000/2000 [00:31<00:00, 62.64it/s]\n",
      "epoch 216 each step reward:1.000:   1%|          | 14/2000 [00:00<00:29, 66.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 22.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 216 avg_loss: 0.035 total_reward [train:26.000 test:21.000] e-greedy:0.389: 100%|██████████| 2000/2000 [00:31<00:00, 63.26it/s]\n",
      "epoch 217 avg_loss: 0.034 total_reward [train:23.000 test:21.000] e-greedy:0.391: 100%|██████████| 2000/2000 [00:32<00:00, 62.20it/s]\n",
      "epoch 218 avg_loss: 0.034 total_reward [train:29.000 test:20.000] e-greedy:0.392: 100%|██████████| 2000/2000 [00:31<00:00,  8.50it/s]\n",
      "epoch 219 avg_loss: 0.034 total_reward [train:28.000 test:22.000] e-greedy:0.394: 100%|██████████| 2000/2000 [00:31<00:00, 62.98it/s]\n",
      "epoch 220 avg_loss: 0.034 total_reward [train:26.000 test:21.000] e-greedy:0.396: 100%|██████████| 2000/2000 [00:31<00:00, 63.25it/s]\n",
      "epoch 221 each step reward:0.000:   1%|          | 14/2000 [00:00<00:28, 69.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 22.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 221 avg_loss: 0.037 total_reward [train:29.000 test:21.000] e-greedy:0.398: 100%|██████████| 2000/2000 [00:32<00:00,  7.17it/s]\n",
      "epoch 222 avg_loss: 0.037 total_reward [train:27.000 test:20.000] e-greedy:0.400: 100%|██████████| 2000/2000 [00:31<00:00, 63.71it/s]\n",
      "epoch 223 avg_loss: 0.036 total_reward [train:24.000 test:19.000] e-greedy:0.401: 100%|██████████| 2000/2000 [00:29<00:00, 67.37it/s]\n",
      "epoch 224 avg_loss: 0.035 total_reward [train:27.000 test:10.000] e-greedy:0.403: 100%|██████████| 2000/2000 [00:29<00:00, 67.09it/s]\n",
      "epoch 225 avg_loss: 0.035 total_reward [train:27.000 test:18.000] e-greedy:0.405: 100%|██████████| 2000/2000 [00:29<00:00, 72.49it/s]\n",
      "epoch 226 each step reward:0.000:   1%|          | 16/2000 [00:00<00:25, 78.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 226 avg_loss: 0.036 total_reward [train:23.000 test:17.000] e-greedy:0.407: 100%|██████████| 2000/2000 [00:31<00:00, 64.26it/s]\n",
      "epoch 227 avg_loss: 0.037 total_reward [train:33.000 test:21.000] e-greedy:0.409: 100%|██████████| 2000/2000 [00:30<00:00, 64.98it/s]\n",
      "epoch 228 avg_loss: 0.037 total_reward [train:35.000 test:19.000] e-greedy:0.410: 100%|██████████| 2000/2000 [00:31<00:00, 63.90it/s]\n",
      "epoch 229 avg_loss: 0.036 total_reward [train:27.000 test:21.000] e-greedy:0.412: 100%|██████████| 2000/2000 [00:30<00:00, 71.97it/s]\n",
      "epoch 230 avg_loss: 0.036 total_reward [train:22.000 test:20.000] e-greedy:0.414: 100%|██████████| 2000/2000 [00:31<00:00, 63.90it/s]\n",
      "epoch 231 each step reward:0.000:   1%|          | 16/2000 [00:00<00:25, 78.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 231 avg_loss: 0.036 total_reward [train:25.000 test:20.000] e-greedy:0.416: 100%|██████████| 2000/2000 [00:31<00:00, 72.22it/s]\n",
      "epoch 232 avg_loss: 0.036 total_reward [train:30.000 test:18.000] e-greedy:0.418: 100%|██████████| 2000/2000 [00:30<00:00, 64.90it/s]\n",
      "epoch 233 avg_loss: 0.035 total_reward [train:28.000 test:20.000] e-greedy:0.419: 100%|██████████| 2000/2000 [00:32<00:00, 61.77it/s]\n",
      "epoch 234 avg_loss: 0.035 total_reward [train:37.000 test:22.000] e-greedy:0.421: 100%|██████████| 2000/2000 [00:31<00:00, 63.17it/s]\n",
      "epoch 235 avg_loss: 0.035 total_reward [train:29.000 test:17.000] e-greedy:0.423: 100%|██████████| 2000/2000 [00:31<00:00, 62.93it/s]\n",
      "epoch 236 each step reward:0.000:   1%|          | 12/2000 [00:00<00:29, 67.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 22.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 236 avg_loss: 0.036 total_reward [train:37.000 test:18.000] e-greedy:0.425: 100%|██████████| 2000/2000 [00:31<00:00, 63.15it/s]\n",
      "epoch 237 avg_loss: 0.036 total_reward [train:30.000 test:21.000] e-greedy:0.427: 100%|██████████| 2000/2000 [00:30<00:00, 65.09it/s]\n",
      "epoch 238 avg_loss: 0.035 total_reward [train:27.000 test:22.000] e-greedy:0.428: 100%|██████████| 2000/2000 [00:31<00:00, 63.25it/s]\n",
      "epoch 239 avg_loss: 0.035 total_reward [train:32.000 test:21.000] e-greedy:0.430: 100%|██████████| 2000/2000 [00:30<00:00, 64.93it/s]\n",
      "epoch 240 avg_loss: 0.036 total_reward [train:31.000 test:17.000] e-greedy:0.432: 100%|██████████| 2000/2000 [00:30<00:00, 64.82it/s]\n",
      "epoch 241 each step reward:0.000:   0%|          | 10/2000 [00:00<00:52, 37.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 22.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 241 avg_loss: 0.036 total_reward [train:30.000 test:20.000] e-greedy:0.434: 100%|██████████| 2000/2000 [00:31<00:00, 63.60it/s]\n",
      "epoch 242 avg_loss: 0.034 total_reward [train:31.000 test:23.000] e-greedy:0.436: 100%|██████████| 2000/2000 [00:32<00:00, 60.93it/s]\n",
      "epoch 243 avg_loss: 0.035 total_reward [train:34.000 test:16.000] e-greedy:0.437: 100%|██████████| 2000/2000 [00:31<00:00, 63.58it/s]\n",
      "epoch 244 avg_loss: 0.033 total_reward [train:32.000 test:22.000] e-greedy:0.439: 100%|██████████| 2000/2000 [00:31<00:00, 63.95it/s]\n",
      "epoch 245 avg_loss: 0.034 total_reward [train:29.000 test:20.000] e-greedy:0.441: 100%|██████████| 2000/2000 [00:32<00:00, 61.82it/s]\n",
      "epoch 246 each step reward:0.000:   1%|          | 12/2000 [00:00<00:31, 62.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 23.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 246 avg_loss: 0.037 total_reward [train:29.000 test:20.000] e-greedy:0.443: 100%|██████████| 2000/2000 [00:31<00:00, 62.78it/s]\n",
      "epoch 247 avg_loss: 0.036 total_reward [train:38.000 test:18.000] e-greedy:0.445: 100%|██████████| 2000/2000 [00:30<00:00, 64.97it/s]\n",
      "epoch 248 avg_loss: 0.036 total_reward [train:34.000 test:21.000] e-greedy:0.446: 100%|██████████| 2000/2000 [00:31<00:00, 63.54it/s]\n",
      "epoch 249 avg_loss: 0.036 total_reward [train:34.000 test:19.000] e-greedy:0.448: 100%|██████████| 2000/2000 [00:30<00:00, 66.33it/s]\n",
      "epoch 250 avg_loss: 0.036 total_reward [train:36.000 test:22.000] e-greedy:0.450: 100%|██████████| 2000/2000 [00:31<00:00, 62.69it/s]\n",
      "epoch 251 each step reward:0.000:   1%|          | 14/2000 [00:00<00:28, 68.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 22.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 251 avg_loss: 0.038 total_reward [train:31.000 test:17.000] e-greedy:0.452: 100%|██████████| 2000/2000 [00:30<00:00, 64.68it/s]\n",
      "epoch 252 avg_loss: 0.036 total_reward [train:29.000 test:14.000] e-greedy:0.454: 100%|██████████| 2000/2000 [00:32<00:00, 62.40it/s]\n",
      "epoch 253 avg_loss: 0.037 total_reward [train:32.000 test:22.000] e-greedy:0.455: 100%|██████████| 2000/2000 [00:31<00:00, 64.44it/s]\n",
      "epoch 254 avg_loss: 0.036 total_reward [train:28.000 test:23.000] e-greedy:0.457: 100%|██████████| 2000/2000 [00:30<00:00, 65.84it/s]\n",
      "epoch 255 avg_loss: 0.037 total_reward [train:30.000 test:20.000] e-greedy:0.459: 100%|██████████| 2000/2000 [00:31<00:00, 62.85it/s]\n",
      "epoch 256 each step reward:1.000:   1%|          | 17/2000 [00:00<00:24, 81.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 23.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 256 avg_loss: 0.036 total_reward [train:33.000 test:21.000] e-greedy:0.461: 100%|██████████| 2000/2000 [00:29<00:00, 74.48it/s]\n",
      "epoch 257 avg_loss: 0.036 total_reward [train:29.000 test:21.000] e-greedy:0.463: 100%|██████████| 2000/2000 [00:30<00:00, 76.86it/s]\n",
      "epoch 258 avg_loss: 0.035 total_reward [train:31.000 test:18.000] e-greedy:0.464: 100%|██████████| 2000/2000 [00:30<00:00, 69.58it/s]\n",
      "epoch 259 avg_loss: 0.035 total_reward [train:33.000 test:18.000] e-greedy:0.466: 100%|██████████| 2000/2000 [00:30<00:00, 65.59it/s]\n",
      "epoch 260 avg_loss: 0.034 total_reward [train:29.000 test:20.000] e-greedy:0.468: 100%|██████████| 2000/2000 [00:30<00:00, 66.03it/s]\n",
      "epoch 261 each step reward:1.000:   1%|          | 14/2000 [00:00<00:29, 67.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 261 avg_loss: 0.037 total_reward [train:34.000 test:21.000] e-greedy:0.470: 100%|██████████| 2000/2000 [00:29<00:00, 66.67it/s]\n",
      "epoch 262 avg_loss: 0.035 total_reward [train:29.000 test:22.000] e-greedy:0.472: 100%|██████████| 2000/2000 [00:30<00:00, 76.13it/s]\n",
      "epoch 263 avg_loss: 0.036 total_reward [train:34.000 test:21.000] e-greedy:0.473: 100%|██████████| 2000/2000 [00:30<00:00, 66.58it/s]\n",
      "epoch 264 avg_loss: 0.035 total_reward [train:32.000 test:19.000] e-greedy:0.475: 100%|██████████| 2000/2000 [00:30<00:00, 66.24it/s]\n",
      "epoch 265 avg_loss: 0.035 total_reward [train:36.000 test:23.000] e-greedy:0.477: 100%|██████████| 2000/2000 [00:30<00:00, 66.50it/s]\n",
      "epoch 266 each step reward:0.000:   1%|          | 12/2000 [00:00<00:32, 61.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 23.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 266 avg_loss: 0.037 total_reward [train:35.000 test:20.000] e-greedy:0.479: 100%|██████████| 2000/2000 [00:31<00:00, 64.40it/s]\n",
      "epoch 267 avg_loss: 0.036 total_reward [train:33.000 test:21.000] e-greedy:0.481: 100%|██████████| 2000/2000 [00:29<00:00, 67.33it/s]\n",
      "epoch 268 avg_loss: 0.034 total_reward [train:33.000 test:16.000] e-greedy:0.482: 100%|██████████| 2000/2000 [00:30<00:00, 65.22it/s]\n",
      "epoch 269 avg_loss: 0.035 total_reward [train:35.000 test:22.000] e-greedy:0.484: 100%|██████████| 2000/2000 [00:31<00:00, 63.98it/s]\n",
      "epoch 270 avg_loss: 0.034 total_reward [train:37.000 test:21.000] e-greedy:0.486: 100%|██████████| 2000/2000 [00:29<00:00, 66.88it/s]\n",
      "epoch 271 each step reward:0.000:   1%|          | 13/2000 [00:00<00:30, 65.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 22.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 271 avg_loss: 0.038 total_reward [train:37.000 test:21.000] e-greedy:0.488: 100%|██████████| 2000/2000 [00:29<00:00, 67.59it/s]\n",
      "epoch 272 avg_loss: 0.036 total_reward [train:37.000 test:20.000] e-greedy:0.490: 100%|██████████| 2000/2000 [00:30<00:00, 66.12it/s]\n",
      "epoch 273 avg_loss: 0.036 total_reward [train:36.000 test:23.000] e-greedy:0.491: 100%|██████████| 2000/2000 [00:31<00:00, 63.61it/s]\n",
      "epoch 274 avg_loss: 0.037 total_reward [train:36.000 test:21.000] e-greedy:0.493: 100%|██████████| 2000/2000 [00:31<00:00, 63.40it/s]\n",
      "epoch 275 avg_loss: 0.036 total_reward [train:36.000 test:16.000] e-greedy:0.495: 100%|██████████| 2000/2000 [00:31<00:00, 63.18it/s]\n",
      "epoch 276 each step reward:0.000:   1%|          | 11/2000 [00:00<00:41, 48.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 23.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 276 avg_loss: 0.038 total_reward [train:37.000 test:20.000] e-greedy:0.497: 100%|██████████| 2000/2000 [00:31<00:00, 63.95it/s]\n",
      "epoch 277 avg_loss: 0.037 total_reward [train:41.000 test:24.000] e-greedy:0.499: 100%|██████████| 2000/2000 [00:31<00:00, 71.49it/s]\n",
      "epoch 278 avg_loss: 0.036 total_reward [train:37.000 test:21.000] e-greedy:0.500: 100%|██████████| 2000/2000 [00:31<00:00, 63.04it/s]\n",
      "epoch 279 avg_loss: 0.037 total_reward [train:36.000 test:22.000] e-greedy:0.502: 100%|██████████| 2000/2000 [00:31<00:00, 62.56it/s]\n",
      "epoch 280 avg_loss: 0.036 total_reward [train:37.000 test:23.000] e-greedy:0.504: 100%|██████████| 2000/2000 [00:31<00:00, 63.37it/s]\n",
      "epoch 281 each step reward:0.000:   1%|          | 12/2000 [00:00<00:39, 49.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 24.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 281 avg_loss: 0.040 total_reward [train:36.000 test:19.000] e-greedy:0.506: 100%|██████████| 2000/2000 [00:30<00:00, 65.68it/s]\n",
      "epoch 282 avg_loss: 0.038 total_reward [train:37.000 test:23.000] e-greedy:0.508: 100%|██████████| 2000/2000 [00:31<00:00, 62.66it/s]\n",
      "epoch 283 avg_loss: 0.036 total_reward [train:41.000 test:21.000] e-greedy:0.509: 100%|██████████| 2000/2000 [00:31<00:00, 63.38it/s]\n",
      "epoch 284 avg_loss: 0.037 total_reward [train:39.000 test:22.000] e-greedy:0.511: 100%|██████████| 2000/2000 [00:31<00:00, 63.69it/s]\n",
      "epoch 285 avg_loss: 0.037 total_reward [train:36.000 test:23.000] e-greedy:0.513: 100%|██████████| 2000/2000 [00:31<00:00, 62.58it/s]\n",
      "epoch 286 each step reward:0.000:   0%|          | 10/2000 [00:00<00:45, 43.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 23.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 286 avg_loss: 0.041 total_reward [train:38.000 test:19.000] e-greedy:0.515: 100%|██████████| 2000/2000 [00:31<00:00, 63.32it/s]\n",
      "epoch 287 avg_loss: 0.039 total_reward [train:37.000 test:19.000] e-greedy:0.517: 100%|██████████| 2000/2000 [00:31<00:00, 62.92it/s]\n",
      "epoch 288 avg_loss: 0.039 total_reward [train:37.000 test:20.000] e-greedy:0.518: 100%|██████████| 2000/2000 [00:31<00:00, 64.09it/s]\n",
      "epoch 289 avg_loss: 0.040 total_reward [train:40.000 test:22.000] e-greedy:0.520: 100%|██████████| 2000/2000 [00:31<00:00, 63.56it/s]\n",
      "epoch 290 avg_loss: 0.038 total_reward [train:38.000 test:20.000] e-greedy:0.522: 100%|██████████| 2000/2000 [00:31<00:00, 64.38it/s]\n",
      "epoch 291 each step reward:0.000:   1%|          | 16/2000 [00:00<00:25, 77.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 22.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 291 avg_loss: 0.039 total_reward [train:36.000 test:22.000] e-greedy:0.524: 100%|██████████| 2000/2000 [00:31<00:00, 64.14it/s]\n",
      "epoch 292 avg_loss: 0.037 total_reward [train:37.000 test:22.000] e-greedy:0.526: 100%|██████████| 2000/2000 [00:31<00:00, 63.36it/s]\n",
      "epoch 293 avg_loss: 0.037 total_reward [train:38.000 test:23.000] e-greedy:0.527: 100%|██████████| 2000/2000 [00:30<00:00, 66.01it/s]\n",
      "epoch 294 avg_loss: 0.037 total_reward [train:34.000 test:22.000] e-greedy:0.529: 100%|██████████| 2000/2000 [00:31<00:00, 63.33it/s]\n",
      "epoch 295 avg_loss: 0.037 total_reward [train:37.000 test:22.000] e-greedy:0.531: 100%|██████████| 2000/2000 [00:30<00:00, 68.11it/s]\n",
      "epoch 296 each step reward:0.000:   1%|          | 16/2000 [00:00<00:26, 76.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 23.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 296 avg_loss: 0.040 total_reward [train:37.000 test:21.000] e-greedy:0.533: 100%|██████████| 2000/2000 [00:29<00:00,  8.75it/s]\n",
      "epoch 297 avg_loss: 0.038 total_reward [train:36.000 test:24.000] e-greedy:0.535: 100%|██████████| 2000/2000 [00:29<00:00, 67.37it/s]\n",
      "epoch 298 avg_loss: 0.038 total_reward [train:34.000 test:21.000] e-greedy:0.536: 100%|██████████| 2000/2000 [00:29<00:00, 67.08it/s]\n",
      "epoch 299 avg_loss: 0.038 total_reward [train:42.000 test:22.000] e-greedy:0.538: 100%|██████████| 2000/2000 [00:31<00:00, 63.69it/s]\n",
      "epoch 300 avg_loss: 0.038 total_reward [train:38.000 test:23.000] e-greedy:0.540: 100%|██████████| 2000/2000 [00:31<00:00, 63.98it/s]\n",
      "epoch 301 each step reward:0.000:   1%|          | 14/2000 [00:00<00:29, 67.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 24.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 301 avg_loss: 0.039 total_reward [train:39.000 test:25.000] e-greedy:0.542: 100%|██████████| 2000/2000 [00:31<00:00, 64.29it/s]\n",
      "epoch 302 avg_loss: 0.039 total_reward [train:39.000 test:21.000] e-greedy:0.544: 100%|██████████| 2000/2000 [00:31<00:00, 63.03it/s]\n",
      "epoch 303 avg_loss: 0.037 total_reward [train:36.000 test:25.000] e-greedy:0.545: 100%|██████████| 2000/2000 [00:31<00:00, 63.19it/s]\n",
      "epoch 304 avg_loss: 0.038 total_reward [train:41.000 test:23.000] e-greedy:0.547: 100%|██████████| 2000/2000 [00:31<00:00, 63.44it/s]\n",
      "epoch 305 avg_loss: 0.039 total_reward [train:37.000 test:22.000] e-greedy:0.549: 100%|██████████| 2000/2000 [00:32<00:00, 62.14it/s]\n",
      "epoch 306 each step reward:0.000:   1%|          | 14/2000 [00:00<00:30, 65.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 25.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 306 avg_loss: 0.042 total_reward [train:42.000 test:26.000] e-greedy:0.551: 100%|██████████| 2000/2000 [00:31<00:00, 63.85it/s]\n",
      "epoch 307 avg_loss: 0.040 total_reward [train:40.000 test:22.000] e-greedy:0.553: 100%|██████████| 2000/2000 [00:31<00:00, 64.25it/s]\n",
      "epoch 308 avg_loss: 0.040 total_reward [train:38.000 test:22.000] e-greedy:0.554: 100%|██████████| 2000/2000 [00:31<00:00, 64.03it/s]\n",
      "epoch 309 avg_loss: 0.039 total_reward [train:40.000 test:22.000] e-greedy:0.556: 100%|██████████| 2000/2000 [00:29<00:00, 72.20it/s]\n",
      "epoch 310 avg_loss: 0.039 total_reward [train:38.000 test:24.000] e-greedy:0.558: 100%|██████████| 2000/2000 [00:29<00:00, 66.96it/s]\n",
      "epoch 311 each step reward:0.000:   1%|          | 14/2000 [00:00<00:28, 70.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 26.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 311 avg_loss: 0.040 total_reward [train:38.000 test:22.000] e-greedy:0.560: 100%|██████████| 2000/2000 [00:29<00:00, 66.70it/s]\n",
      "epoch 312 avg_loss: 0.039 total_reward [train:41.000 test:20.000] e-greedy:0.562: 100%|██████████| 2000/2000 [00:30<00:00, 66.51it/s]\n",
      "epoch 313 avg_loss: 0.037 total_reward [train:41.000 test:24.000] e-greedy:0.563: 100%|██████████| 2000/2000 [00:29<00:00, 67.77it/s]\n",
      "epoch 314 avg_loss: 0.038 total_reward [train:42.000 test:23.000] e-greedy:0.565: 100%|██████████| 2000/2000 [00:30<00:00, 66.36it/s]\n",
      "epoch 315 avg_loss: 0.038 total_reward [train:41.000 test:24.000] e-greedy:0.567: 100%|██████████| 2000/2000 [00:31<00:00, 71.81it/s]\n",
      "epoch 316 each step reward:0.000:   1%|          | 14/2000 [00:00<00:27, 71.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 24.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 316 avg_loss: 0.044 total_reward [train:39.000 test:23.000] e-greedy:0.569: 100%|██████████| 2000/2000 [00:31<00:00, 63.97it/s]\n",
      "epoch 317 avg_loss: 0.044 total_reward [train:45.000 test:23.000] e-greedy:0.571: 100%|██████████| 2000/2000 [00:31<00:00, 63.96it/s]\n",
      "epoch 318 each step reward:37.000:  90%|█████████ | 1800/2000 [00:30<00:03, 55.75it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-6c7d4ea3a04f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgreedy_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_period\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/local_repository/ReNomRL/renom_rl/discrete/dqn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epoch, epoch_step, batch_size, random_step, test_step, update_period, train_frequency, min_greedy, max_greedy, greedy_step, test_greedy, render, callback_end_epoch)\u001b[0m\n\u001b[1;32m    282\u001b[0m                         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_q_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_prestate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m                         \u001b[0mls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m                     \u001b[0mls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/local_repository/ReNom/renom/core.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(self, initial, detach_graph, **kwargs)\u001b[0m\n\u001b[1;32m    440\u001b[0m                 \u001b[0minitial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m         \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGrads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_diff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/local_repository/ReNom/renom/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mroot\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_refcounts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_build_refcounts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/local_repository/ReNom/renom/core.py\u001b[0m in \u001b[0;36m_build_refcounts\u001b[0;34m(self, root)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mnodeid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0mseen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodeid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_refcounts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_refcounts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnodeid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mseen\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_no_backward'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch 318 each step reward:37.000:  90%|█████████ | 1801/2000 [00:50<00:03, 55.75it/s]"
     ]
    }
   ],
   "source": [
    "result = model.fit(render=False, greedy_step=1000000, random_step=5000, update_period=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_network.save(\"dqn_exp5.h5\")\n",
    "# model = DQN(custom_env, q_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.test(render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_t = time.time()\n",
    "a = np.random.permutation(int(1e1))\n",
    "print(time.time()-start_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
