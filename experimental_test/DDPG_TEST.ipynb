{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary packages tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import renom as rm\n",
    "from renom.utility.initializer import Uniform, GlorotUniform\n",
    "from renom_rl.ddpg import DDPG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deifne the environment tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "(1,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('Pendulum-v0')\n",
    "print(env.action_space.shape)\n",
    "print(env.observation_space.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the actor network tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor(rm.Model):\n",
    "    \n",
    "    '''Here considered 3-layer network (excluding input layer). Feel free to change the network depth \n",
    "    and check the results. The output-layer number of nuerons are equal to number of actions.\n",
    "    In the example of OpenAI Gym's Pendlum-v0 environment number of actions are 1.'''\n",
    "    \n",
    "    def __init__(self, env, layer_size):\n",
    "        self._layers = []\n",
    "        self.env = env\n",
    "        self.action_size = self.env.action_space.shape[0] if hasattr(self.env, \"action_space\") else env.action_size\n",
    "        self.high = self.env.action_space.high[0] if hasattr(self.env, \"action_space\") else env.high\n",
    "        self._l1 = rm.Dense(400, initializer=GlorotUniform())\n",
    "        self._l2 = rm.Dense(300, initializer=GlorotUniform())\n",
    "        self._l3 = rm.Dense(self.action_size, initializer=Uniform(min=-0.003, max=0.003))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        '''Neural Network inputs are state information, outputs are actions. '''\n",
    "        h1 = rm.relu(self._l1(x))\n",
    "        h2 = rm.relu(self._l2(h1))\n",
    "        h3 = rm.tanh(self._l3(h2)) \n",
    "        h = h3*self.high\n",
    "        return h\n",
    "    \n",
    "    def weigiht_decay(self):\n",
    "        '''To minimize over fitting considered L2-norm (it is an optional)'''\n",
    "        weight_decay = 0\n",
    "        for i in range(len(self._layers)):\n",
    "            weight_decay += rm.sum(self._layers[i].params.w**2)\n",
    "        return weight_decay\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Critic network tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(rm.Model):\n",
    "    '''Here considered a 3-layer network (input layer, hidden layer-1, hidden layer-2, output layer)\n",
    "        At input-layer state information, 2nd-hidden layer actions are applied, last layer has a single neuron'''\n",
    "    def __init__(self, env, layer_size):        \n",
    "        self._layers = []\n",
    "        self.env = env\n",
    "        self._l1 = rm.Dense(layer_size[0], initializer=GlorotUniform())\n",
    "        self._l2 = rm.Dense(layer_size[1], initializer=GlorotUniform())\n",
    "        self._l3 = rm.Dense(1, initializer=Uniform(min=-0.003, max=0.003))\n",
    "  \n",
    "    def forward(self, x, action):\n",
    "        '''Q(s,a) calculation for a given (state, action) pair'''\n",
    "        h1 = rm.relu(self._l1(x))\n",
    "        h2 = rm.relu(self._l2(rm.concat(h1, action))) # actions are applied at 2nd hidden layer\n",
    "        h = self._l3(h2)        \n",
    "        return h\n",
    "    \n",
    "    def weigiht_decay(self):\n",
    "        '''To minimize over fitting considered L2-norm (it is an optional)'''\n",
    "        weight_decay = 0\n",
    "        for i in range(len(self._layers)):\n",
    "            weight_decay += rm.sum(self._layers[i].params.w**2)\n",
    "        return weight_decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiating the actor & ciritic networks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_size = [400, 300] # two-hidden layers dimension\n",
    "actor_network = Actor(env=env,layer_size=layer_size)\n",
    "critic_network = Critic(env=env, layer_size=layer_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiating the DDPG class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg = DDPG(env, actor_network, critic_network, loss_func=lambda x, y:rm.mse(x, y) + 0.0001*critic_network.weigiht_decay())\n",
    "# ddpg = DDPG(env=env) # for default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode 001 avg_loss: 2.870 total_reward [train:-1608.949 test:-] exploration:0.993: 100%|██████████| 200/200 [00:05<00:00, 37.40it/s]\n",
      "episode 002 avg_loss: 0.123 total_reward [train:-1203.914 test:-] exploration:0.987: 100%|██████████| 200/200 [00:05<00:00, 38.65it/s]\n",
      "episode 003 avg_loss: 0.027 total_reward [train:-1638.847 test:-] exploration:0.980: 100%|██████████| 200/200 [00:05<00:00, 34.86it/s]\n",
      "episode 004 avg_loss: 0.016 total_reward [train:-1491.019 test:-] exploration:0.973: 100%|██████████| 200/200 [00:06<00:00, 32.53it/s]\n",
      "episode 005 avg_loss: 0.013 total_reward [train:-1567.252 test:-] exploration:0.967: 100%|██████████| 200/200 [00:06<00:00, 26.91it/s]\n",
      "episode 006 avg_loss: 0.015 total_reward [train:-1188.995 test:-] exploration:0.960: 100%|██████████| 200/200 [00:05<00:00, 34.69it/s]\n",
      "episode 007 avg_loss: 0.019 total_reward [train:-1569.526 test:-] exploration:0.953: 100%|██████████| 200/200 [00:06<00:00, 29.06it/s]\n",
      "episode 008 avg_loss: 0.024 total_reward [train:-1156.902 test:-] exploration:0.947: 100%|██████████| 200/200 [00:05<00:00, 34.62it/s]\n",
      "episode 009 avg_loss: 0.018 total_reward [train:-1642.577 test:-] exploration:0.940: 100%|██████████| 200/200 [00:06<00:00, 29.76it/s]\n",
      "episode 010 avg_loss: 0.016 total_reward [train:-1798.366 test:-1713.988] exploration:0.933: 100%|██████████| 200/200 [00:06<00:00, 33.32it/s]\n",
      "episode 011 avg_loss: 0.016 total_reward [train:-1661.944 test:-] exploration:0.927: 100%|██████████| 200/200 [00:05<00:00, 35.46it/s]\n",
      "episode 012 avg_loss: 0.012 total_reward [train:-1501.690 test:-] exploration:0.920: 100%|██████████| 200/200 [00:07<00:00, 26.82it/s]\n",
      "episode 013 avg_loss: 0.024 total_reward [train:-1577.933 test:-] exploration:0.913: 100%|██████████| 200/200 [00:06<00:00, 31.35it/s]\n",
      "episode 014 avg_loss: 0.010 total_reward [train:-1531.886 test:-] exploration:0.907: 100%|██████████| 200/200 [00:06<00:00, 29.25it/s]\n",
      "episode 015 avg_loss: 0.010 total_reward [train:-1546.107 test:-] exploration:0.900: 100%|██████████| 200/200 [00:07<00:00, 27.17it/s]\n",
      "episode 016 avg_loss: 0.010 total_reward [train:-1579.016 test:-] exploration:0.893: 100%|██████████| 200/200 [00:07<00:00, 26.03it/s]\n",
      "episode 017 avg_loss: 0.011 total_reward [train:-1512.602 test:-] exploration:0.887: 100%|██████████| 200/200 [00:06<00:00, 29.25it/s]\n",
      "episode 018 avg_loss: 0.011 total_reward [train:-1644.581 test:-] exploration:0.880: 100%|██████████| 200/200 [00:07<00:00, 27.48it/s]\n",
      "episode 019 avg_loss: 0.007 total_reward [train:-1633.171 test:-] exploration:0.873: 100%|██████████| 200/200 [00:06<00:00, 33.26it/s]\n",
      "episode 020 avg_loss: 0.007 total_reward [train:-1567.346 test:-1660.619] exploration:0.867: 100%|██████████| 200/200 [00:06<00:00, 29.31it/s]\n",
      "episode 021 avg_loss: 0.017 total_reward [train:-1426.971 test:-] exploration:0.860: 100%|██████████| 200/200 [00:07<00:00, 27.87it/s]\n",
      "episode 022 avg_loss: 0.010 total_reward [train:-1624.787 test:-] exploration:0.853: 100%|██████████| 200/200 [00:07<00:00, 30.47it/s]\n",
      "episode 023 avg_loss: 0.008 total_reward [train:-1440.220 test:-] exploration:0.847: 100%|██████████| 200/200 [00:06<00:00, 29.05it/s]\n",
      "episode 024 avg_loss: 0.018 total_reward [train:-1655.362 test:-] exploration:0.840: 100%|██████████| 200/200 [00:07<00:00, 27.32it/s]\n",
      "episode 025 avg_loss: 0.007 total_reward [train:-1554.187 test:-] exploration:0.833: 100%|██████████| 200/200 [00:06<00:00, 29.13it/s]\n",
      "episode 026 avg_loss: 0.007 total_reward [train:-1697.199 test:-] exploration:0.827: 100%|██████████| 200/200 [00:07<00:00, 27.86it/s]\n",
      "episode 027 avg_loss: 0.008 total_reward [train:-1660.109 test:-] exploration:0.820: 100%|██████████| 200/200 [00:05<00:00, 34.08it/s]\n",
      "episode 028 avg_loss: 0.009 total_reward [train:-1604.813 test:-] exploration:0.813: 100%|██████████| 200/200 [00:06<00:00, 29.05it/s]\n",
      "episode 029 avg_loss: 0.008 total_reward [train:-1655.538 test:-] exploration:0.807: 100%|██████████| 200/200 [00:06<00:00, 30.25it/s]\n",
      "episode 030 avg_loss: 0.010 total_reward [train:-1675.206 test:-1689.869] exploration:0.800: 100%|██████████| 200/200 [00:07<00:00, 27.48it/s]\n",
      "episode 031 avg_loss: 0.010 total_reward [train:-1621.303 test:-] exploration:0.793: 100%|██████████| 200/200 [00:06<00:00, 31.29it/s]\n",
      "episode 032 avg_loss: 0.013 total_reward [train:-1711.556 test:-] exploration:0.787: 100%|██████████| 200/200 [00:05<00:00, 35.19it/s]\n",
      "episode 033 avg_loss: 0.009 total_reward [train:-1587.226 test:-] exploration:0.780: 100%|██████████| 200/200 [00:06<00:00, 29.46it/s]\n",
      "episode 034 avg_loss: 0.012 total_reward [train:-1560.939 test:-] exploration:0.773: 100%|██████████| 200/200 [00:05<00:00, 35.56it/s]\n",
      "episode 035 avg_loss: 0.014 total_reward [train:-1773.805 test:-] exploration:0.767: 100%|██████████| 200/200 [00:07<00:00, 28.46it/s]\n",
      "episode 036 avg_loss: 0.011 total_reward [train:-1538.364 test:-] exploration:0.760: 100%|██████████| 200/200 [00:06<00:00, 30.13it/s]\n",
      "episode 037 avg_loss: 0.010 total_reward [train:-1484.884 test:-] exploration:0.753: 100%|██████████| 200/200 [00:06<00:00, 33.10it/s]\n",
      "episode 038 avg_loss: 0.012 total_reward [train:-1670.062 test:-] exploration:0.747: 100%|██████████| 200/200 [00:06<00:00, 37.91it/s]\n",
      "episode 039 avg_loss: 0.016 total_reward [train:-1433.192 test:-] exploration:0.740: 100%|██████████| 200/200 [00:07<00:00, 25.48it/s]\n",
      "episode 040 avg_loss: 0.011 total_reward [train:-1537.382 test:-1504.989] exploration:0.733: 100%|██████████| 200/200 [00:06<00:00, 28.76it/s]\n",
      "episode 041 avg_loss: 0.016 total_reward [train:-1409.672 test:-] exploration:0.727: 100%|██████████| 200/200 [00:06<00:00, 29.50it/s]\n",
      "episode 042 avg_loss: 0.011 total_reward [train:-1561.622 test:-] exploration:0.720: 100%|██████████| 200/200 [00:06<00:00, 30.57it/s]\n",
      "episode 043 avg_loss: 0.012 total_reward [train:-1405.936 test:-] exploration:0.713: 100%|██████████| 200/200 [00:06<00:00, 29.59it/s]\n",
      "episode 044 avg_loss: 0.011 total_reward [train:-1479.700 test:-] exploration:0.707: 100%|██████████| 200/200 [00:06<00:00, 29.59it/s]\n",
      "episode 045 avg_loss: 0.023 total_reward [train:-1381.628 test:-] exploration:0.700: 100%|██████████| 200/200 [00:07<00:00, 27.31it/s]\n",
      "episode 046 avg_loss: 0.008 total_reward [train:-1382.639 test:-] exploration:0.693: 100%|██████████| 200/200 [00:07<00:00, 27.23it/s]\n",
      "episode 047 avg_loss: 0.011 total_reward [train:-1367.865 test:-] exploration:0.687: 100%|██████████| 200/200 [00:06<00:00, 29.29it/s]\n",
      "episode 048 avg_loss: 0.014 total_reward [train:-1395.939 test:-] exploration:0.680: 100%|██████████| 200/200 [00:06<00:00, 29.96it/s]\n",
      "episode 049 avg_loss: 0.014 total_reward [train:-1362.693 test:-] exploration:0.673: 100%|██████████| 200/200 [00:06<00:00, 31.26it/s]\n",
      "episode 050 avg_loss: 0.017 total_reward [train:-1405.842 test:-1363.111] exploration:0.667: 100%|██████████| 200/200 [00:06<00:00, 32.54it/s]\n",
      "episode 051 avg_loss: 0.011 total_reward [train:-1330.908 test:-] exploration:0.660: 100%|██████████| 200/200 [00:06<00:00, 31.07it/s]\n",
      "episode 052 avg_loss: 0.010 total_reward [train:-1375.569 test:-] exploration:0.653: 100%|██████████| 200/200 [00:05<00:00, 35.45it/s]\n",
      "episode 053 avg_loss: 0.013 total_reward [train:-1330.501 test:-] exploration:0.647: 100%|██████████| 200/200 [00:07<00:00, 28.81it/s]\n",
      "episode 054 avg_loss: 0.014 total_reward [train:-1410.121 test:-] exploration:0.640: 100%|██████████| 200/200 [00:06<00:00, 29.80it/s]\n",
      "episode 055 avg_loss: 0.010 total_reward [train:-1396.958 test:-] exploration:0.633: 100%|██████████| 200/200 [00:07<00:00, 27.75it/s]\n",
      "episode 056 avg_loss: 0.014 total_reward [train:-1344.238 test:-] exploration:0.627: 100%|██████████| 200/200 [00:06<00:00, 29.08it/s]\n",
      "episode 057 avg_loss: 0.027 total_reward [train:-1345.653 test:-] exploration:0.620: 100%|██████████| 200/200 [00:07<00:00, 26.95it/s]\n",
      "episode 058 avg_loss: 0.013 total_reward [train:-1459.981 test:-] exploration:0.613: 100%|██████████| 200/200 [00:06<00:00, 28.95it/s]\n",
      "episode 059 avg_loss: 0.013 total_reward [train:-1298.907 test:-] exploration:0.607: 100%|██████████| 200/200 [00:07<00:00, 27.59it/s]\n",
      "episode 060 avg_loss: 0.011 total_reward [train:-1389.878 test:-1404.472] exploration:0.600: 100%|██████████| 200/200 [00:06<00:00, 29.66it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode 061 avg_loss: 0.007 total_reward [train:-1454.938 test:-] exploration:0.593: 100%|██████████| 200/200 [00:06<00:00, 31.48it/s]\n",
      "episode 062 avg_loss: 0.024 total_reward [train:-1416.395 test:-] exploration:0.587: 100%|██████████| 200/200 [00:06<00:00, 29.40it/s]\n",
      "episode 063 avg_loss: 0.011 total_reward [train:-1538.415 test:-] exploration:0.580: 100%|██████████| 200/200 [00:06<00:00, 31.00it/s]\n",
      "episode 064 avg_loss: 0.018 total_reward [train:-1343.822 test:-] exploration:0.573: 100%|██████████| 200/200 [00:06<00:00, 27.15it/s]\n",
      "episode 065 avg_loss: 0.008 total_reward [train:-1394.924 test:-] exploration:0.567: 100%|██████████| 200/200 [00:06<00:00, 29.58it/s]\n",
      "episode 066 avg_loss: 0.014 total_reward [train:-1279.133 test:-] exploration:0.560: 100%|██████████| 200/200 [00:06<00:00, 27.03it/s]\n",
      "episode 067 avg_loss: 0.014 total_reward [train:-1298.689 test:-] exploration:0.553: 100%|██████████| 200/200 [00:06<00:00, 32.59it/s]\n",
      "episode 068 avg_loss: 0.013 total_reward [train:-1311.338 test:-] exploration:0.547: 100%|██████████| 200/200 [00:05<00:00, 34.89it/s]\n",
      "episode 069 avg_loss: 0.014 total_reward [train:-1262.914 test:-] exploration:0.540: 100%|██████████| 200/200 [00:06<00:00, 32.60it/s]\n",
      "episode 070 avg_loss: 0.012 total_reward [train:-1237.572 test:-1354.975] exploration:0.533: 100%|██████████| 200/200 [00:06<00:00, 28.98it/s]\n",
      "episode 071 avg_loss: 0.019 total_reward [train:-1389.052 test:-] exploration:0.527: 100%|██████████| 200/200 [00:07<00:00, 31.01it/s]\n",
      "episode 072 avg_loss: 0.019 total_reward [train:-1400.660 test:-] exploration:0.520: 100%|██████████| 200/200 [00:07<00:00, 30.67it/s]\n",
      "episode 073 avg_loss: 0.017 total_reward [train:-1167.127 test:-] exploration:0.513: 100%|██████████| 200/200 [00:05<00:00, 34.88it/s]\n",
      "episode 074 avg_loss: 0.009 total_reward [train:-1235.000 test:-] exploration:0.507: 100%|██████████| 200/200 [00:06<00:00, 30.91it/s]\n",
      "episode 075 avg_loss: 0.012 total_reward [train:-1187.823 test:-] exploration:0.500: 100%|██████████| 200/200 [00:06<00:00, 30.10it/s]\n",
      "episode 076 avg_loss: 0.010 total_reward [train:-1187.772 test:-] exploration:0.493: 100%|██████████| 200/200 [00:06<00:00, 30.11it/s]\n",
      "episode 077 avg_loss: 0.012 total_reward [train:-1201.094 test:-] exploration:0.487: 100%|██████████| 200/200 [00:06<00:00, 32.57it/s]\n",
      "episode 078 avg_loss: 0.008 total_reward [train:-1205.582 test:-] exploration:0.480: 100%|██████████| 200/200 [00:06<00:00, 33.25it/s]\n",
      "episode 079 avg_loss: 0.031 total_reward [train:-1199.556 test:-] exploration:0.473: 100%|██████████| 200/200 [00:07<00:00, 26.91it/s]\n",
      "episode 080 avg_loss: 0.009 total_reward [train:-1220.575 test:-1195.019] exploration:0.467: 100%|██████████| 200/200 [00:07<00:00, 27.14it/s]\n",
      "episode 081 avg_loss: 0.007 total_reward [train:-1193.364 test:-] exploration:0.460: 100%|██████████| 200/200 [00:05<00:00, 38.35it/s]\n",
      "episode 082 avg_loss: 0.013 total_reward [train:-1048.910 test:-] exploration:0.453: 100%|██████████| 200/200 [00:06<00:00, 30.62it/s]\n",
      "episode 083 avg_loss: 0.015 total_reward [train:-1179.785 test:-] exploration:0.447: 100%|██████████| 200/200 [00:06<00:00, 26.79it/s]\n",
      "episode 084 avg_loss: 0.013 total_reward [train:-1303.273 test:-] exploration:0.440: 100%|██████████| 200/200 [00:07<00:00, 27.96it/s]\n",
      "episode 085 avg_loss: 0.015 total_reward [train:-1094.651 test:-] exploration:0.433: 100%|██████████| 200/200 [00:08<00:00, 24.91it/s]\n",
      "episode 086 avg_loss: 0.019 total_reward [train:-1073.496 test:-] exploration:0.427: 100%|██████████| 200/200 [00:07<00:00, 28.04it/s]\n",
      "episode 087 avg_loss: 0.021 total_reward [train:-1084.677 test:-] exploration:0.420: 100%|██████████| 200/200 [00:06<00:00, 31.39it/s]\n",
      "episode 088 avg_loss: 0.012 total_reward [train:-1170.954 test:-] exploration:0.413: 100%|██████████| 200/200 [00:05<00:00, 34.45it/s]\n",
      "episode 089 avg_loss: 0.014 total_reward [train:-1061.158 test:-] exploration:0.407: 100%|██████████| 200/200 [00:06<00:00, 29.98it/s]\n",
      "episode 090 avg_loss: 0.015 total_reward [train:-1103.933 test:-1065.247] exploration:0.400: 100%|██████████| 200/200 [00:05<00:00, 33.45it/s]\n",
      "episode 091 avg_loss: 0.016 total_reward [train:-1106.378 test:-] exploration:0.393: 100%|██████████| 200/200 [00:06<00:00, 33.17it/s]\n",
      "episode 092 avg_loss: 0.012 total_reward [train:-1087.300 test:-] exploration:0.387: 100%|██████████| 200/200 [00:06<00:00, 29.88it/s]\n",
      "episode 093 avg_loss: 0.011 total_reward [train:-1064.427 test:-] exploration:0.380: 100%|██████████| 200/200 [00:06<00:00, 32.61it/s]\n",
      "episode 094 avg_loss: 0.047 total_reward [train:-1063.582 test:-] exploration:0.373: 100%|██████████| 200/200 [00:06<00:00, 39.42it/s]\n",
      "episode 095 avg_loss: 0.026 total_reward [train:-1162.131 test:-] exploration:0.367: 100%|██████████| 200/200 [00:06<00:00, 30.23it/s]\n",
      "episode 096 avg_loss: 0.005 total_reward [train:-992.779 test:-] exploration:0.360: 100%|██████████| 200/200 [00:06<00:00, 29.37it/s]\n",
      "episode 097 avg_loss: 0.011 total_reward [train:-1068.591 test:-] exploration:0.353: 100%|██████████| 200/200 [00:06<00:00, 31.73it/s]\n",
      "episode 098 avg_loss: 0.006 total_reward [train:-1163.248 test:-] exploration:0.347: 100%|██████████| 200/200 [00:06<00:00, 28.79it/s]\n",
      "episode 099 avg_loss: 0.011 total_reward [train:-1200.895 test:-] exploration:0.340: 100%|██████████| 200/200 [00:06<00:00, 30.84it/s]\n",
      "episode 100 avg_loss: 0.021 total_reward [train:-1114.635 test:-1067.328] exploration:0.333: 100%|██████████| 200/200 [00:05<00:00, 25.04it/s]\n",
      "episode 101 avg_loss: 0.015 total_reward [train:-1036.165 test:-] exploration:0.327: 100%|██████████| 200/200 [00:07<00:00, 27.81it/s]\n",
      "episode 102 avg_loss: 0.011 total_reward [train:-975.144 test:-] exploration:0.320: 100%|██████████| 200/200 [00:06<00:00, 35.55it/s]\n",
      "episode 103 avg_loss: 0.009 total_reward [train:-1053.543 test:-] exploration:0.313: 100%|██████████| 200/200 [00:06<00:00, 31.42it/s]\n",
      "episode 104 avg_loss: 0.014 total_reward [train:-1072.111 test:-] exploration:0.307: 100%|██████████| 200/200 [00:06<00:00, 32.55it/s]\n",
      "episode 105 avg_loss: 0.019 total_reward [train:-837.008 test:-] exploration:0.300: 100%|██████████| 200/200 [00:07<00:00, 24.47it/s]\n",
      "episode 106 avg_loss: 0.022 total_reward [train:-1041.360 test:-] exploration:0.293: 100%|██████████| 200/200 [00:07<00:00, 33.36it/s]\n",
      "episode 107 avg_loss: 0.019 total_reward [train:-1073.769 test:-] exploration:0.287: 100%|██████████| 200/200 [00:06<00:00, 30.45it/s]\n",
      "episode 108 avg_loss: 0.009 total_reward [train:-1062.897 test:-] exploration:0.280: 100%|██████████| 200/200 [00:06<00:00, 40.56it/s]\n",
      "episode 109 avg_loss: 0.009 total_reward [train:-1106.499 test:-] exploration:0.273: 100%|██████████| 200/200 [00:06<00:00, 28.62it/s]\n",
      "episode 110 avg_loss: 0.013 total_reward [train:-1092.654 test:-1082.681] exploration:0.267: 100%|██████████| 200/200 [00:06<00:00, 25.96it/s]\n",
      "episode 111 avg_loss: 0.014 total_reward [train:-1082.339 test:-] exploration:0.260: 100%|██████████| 200/200 [00:06<00:00, 32.30it/s]\n",
      "episode 112 avg_loss: 0.018 total_reward [train:-1131.036 test:-] exploration:0.253: 100%|██████████| 200/200 [00:06<00:00, 29.51it/s]\n",
      "episode 113 avg_loss: 0.011 total_reward [train:-1186.060 test:-] exploration:0.247: 100%|██████████| 200/200 [00:06<00:00, 34.43it/s]\n",
      "episode 114 avg_loss: 0.010 total_reward [train:-1202.515 test:-] exploration:0.240: 100%|██████████| 200/200 [00:06<00:00, 39.91it/s]\n",
      "episode 115 avg_loss: 0.012 total_reward [train:-1138.081 test:-] exploration:0.233: 100%|██████████| 200/200 [00:06<00:00, 32.65it/s]\n",
      "episode 116 avg_loss: 0.016 total_reward [train:-1229.399 test:-] exploration:0.227: 100%|██████████| 200/200 [00:06<00:00, 29.42it/s]\n",
      "episode 117 avg_loss: 0.012 total_reward [train:-1204.780 test:-] exploration:0.220: 100%|██████████| 200/200 [00:06<00:00, 29.77it/s]\n",
      "episode 118 avg_loss: 0.013 total_reward [train:-1176.882 test:-] exploration:0.213: 100%|██████████| 200/200 [00:06<00:00, 30.79it/s]\n",
      "episode 119 avg_loss: 0.012 total_reward [train:-1167.855 test:-] exploration:0.207: 100%|██████████| 200/200 [00:05<00:00, 35.61it/s]\n",
      "episode 120 avg_loss: 0.021 total_reward [train:-1226.560 test:-1217.578] exploration:0.200: 100%|██████████| 200/200 [00:06<00:00, 32.78it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode 121 avg_loss: 0.006 total_reward [train:-1174.126 test:-] exploration:0.193: 100%|██████████| 200/200 [00:07<00:00, 28.43it/s]\n",
      "episode 122 avg_loss: 0.009 total_reward [train:-1185.604 test:-] exploration:0.187: 100%|██████████| 200/200 [00:07<00:00, 27.26it/s]\n",
      "episode 123 avg_loss: 0.013 total_reward [train:-1201.778 test:-] exploration:0.180: 100%|██████████| 200/200 [00:07<00:00, 32.61it/s]\n",
      "episode 124 avg_loss: 0.007 total_reward [train:-1178.804 test:-] exploration:0.173: 100%|██████████| 200/200 [00:06<00:00, 29.82it/s]\n",
      "episode 125 avg_loss: 0.005 total_reward [train:-1196.088 test:-] exploration:0.167: 100%|██████████| 200/200 [00:05<00:00, 34.90it/s]\n",
      "episode 126 avg_loss: 0.013 total_reward [train:-1190.439 test:-] exploration:0.160: 100%|██████████| 200/200 [00:05<00:00, 31.92it/s]\n",
      "episode 127 avg_loss: 0.008 total_reward [train:-1260.394 test:-] exploration:0.153: 100%|██████████| 200/200 [00:06<00:00, 30.19it/s]\n",
      "episode 128 avg_loss: 0.021 total_reward [train:-1232.010 test:-] exploration:0.147: 100%|██████████| 200/200 [00:06<00:00, 30.39it/s]\n",
      "episode 129 avg_loss: 0.009 total_reward [train:-1249.808 test:-] exploration:0.140: 100%|██████████| 200/200 [00:07<00:00, 28.23it/s]\n",
      "episode 130 avg_loss: 0.009 total_reward [train:-1277.408 test:-1317.893] exploration:0.133: 100%|██████████| 200/200 [00:07<00:00, 27.18it/s]\n",
      "episode 131 avg_loss: 0.006 total_reward [train:-1326.341 test:-] exploration:0.127: 100%|██████████| 200/200 [00:07<00:00, 27.14it/s]\n",
      "episode 132 avg_loss: 0.007 total_reward [train:-1339.977 test:-] exploration:0.120: 100%|██████████| 200/200 [00:06<00:00, 29.65it/s]\n",
      "episode 133 avg_loss: 0.006 total_reward [train:-1334.335 test:-] exploration:0.113: 100%|██████████| 200/200 [00:06<00:00, 31.62it/s]\n",
      "episode 134 avg_loss: 0.016 total_reward [train:-1340.732 test:-] exploration:0.107: 100%|██████████| 200/200 [00:06<00:00, 31.25it/s]\n",
      "episode 135 avg_loss: 0.009 total_reward [train:-1336.752 test:-] exploration:0.100: 100%|██████████| 200/200 [00:06<00:00, 38.64it/s]\n",
      "episode 136 avg_loss: 0.004 total_reward [train:-1395.860 test:-] exploration:0.093: 100%|██████████| 200/200 [00:05<00:00, 33.59it/s]\n",
      "episode 137 avg_loss: 0.004 total_reward [train:-1422.030 test:-] exploration:0.087: 100%|██████████| 200/200 [00:06<00:00, 29.83it/s]\n",
      "episode 138 avg_loss: 0.007 total_reward [train:-1432.690 test:-] exploration:0.080: 100%|██████████| 200/200 [00:05<00:00, 34.62it/s]\n",
      "episode 139 avg_loss: 0.007 total_reward [train:-1399.114 test:-] exploration:0.073: 100%|██████████| 200/200 [00:07<00:00, 30.40it/s]\n",
      "episode 140 avg_loss: 0.006 total_reward [train:-1340.856 test:-1364.179] exploration:0.067: 100%|██████████| 200/200 [00:07<00:00, 28.82it/s]\n",
      "episode 141 avg_loss: 0.010 total_reward [train:-1340.807 test:-] exploration:0.060: 100%|██████████| 200/200 [00:06<00:00, 30.51it/s]\n",
      "episode 142 avg_loss: 0.007 total_reward [train:-1316.080 test:-] exploration:0.053: 100%|██████████| 200/200 [00:06<00:00, 31.82it/s]\n",
      "episode 143 avg_loss: 0.006 total_reward [train:-1367.693 test:-] exploration:0.047: 100%|██████████| 200/200 [00:07<00:00, 27.06it/s]\n",
      "episode 144 avg_loss: 0.004 total_reward [train:-1311.142 test:-] exploration:0.040: 100%|██████████| 200/200 [00:06<00:00, 25.51it/s]\n",
      "episode 145 avg_loss: 0.006 total_reward [train:-1292.142 test:-] exploration:0.033: 100%|██████████| 200/200 [00:06<00:00, 30.23it/s]\n",
      "episode 146 avg_loss: 0.007 total_reward [train:-1264.448 test:-] exploration:0.027: 100%|██████████| 200/200 [00:06<00:00, 32.40it/s]\n",
      "episode 147 avg_loss: 0.010 total_reward [train:-1315.878 test:-] exploration:0.020: 100%|██████████| 200/200 [00:06<00:00, 30.49it/s]\n",
      "episode 148 avg_loss: 0.012 total_reward [train:-1303.583 test:-] exploration:0.013: 100%|██████████| 200/200 [00:07<00:00, 27.88it/s]\n",
      "episode 149 avg_loss: 0.004 total_reward [train:-1299.688 test:-] exploration:0.007: 100%|██████████| 200/200 [00:07<00:00, 24.77it/s]\n",
      "episode 150 avg_loss: 0.004 total_reward [train:-1280.638 test:-1271.827] exploration:0.000: 100%|██████████| 200/200 [00:07<00:00, 28.22it/s]\n",
      "episode 151 avg_loss: 0.008 total_reward [train:-1177.263 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 28.84it/s]\n",
      "episode 152 avg_loss: 0.005 total_reward [train:-1304.317 test:-] exploration:0.000: 100%|██████████| 200/200 [00:07<00:00, 27.25it/s]\n",
      "episode 153 avg_loss: 0.005 total_reward [train:-1330.515 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 31.34it/s]\n",
      "episode 154 avg_loss: 0.007 total_reward [train:-1494.610 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 30.38it/s]\n",
      "episode 155 avg_loss: 0.006 total_reward [train:-1511.948 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 28.08it/s]\n",
      "episode 156 avg_loss: 0.004 total_reward [train:-1524.145 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 31.34it/s]\n",
      "episode 157 avg_loss: 0.008 total_reward [train:-1260.275 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 33.19it/s]\n",
      "episode 158 avg_loss: 0.004 total_reward [train:-1495.441 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 32.14it/s]\n",
      "episode 159 avg_loss: 0.005 total_reward [train:-1317.709 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 23.78it/s]\n",
      "episode 160 avg_loss: 0.007 total_reward [train:-1386.302 test:-1303.786] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 29.36it/s]\n",
      "episode 161 avg_loss: 0.005 total_reward [train:-1231.349 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 32.39it/s]\n",
      "episode 162 avg_loss: 0.011 total_reward [train:-1476.731 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 31.89it/s]\n",
      "episode 163 avg_loss: 0.007 total_reward [train:-1375.659 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 29.44it/s]\n",
      "episode 164 avg_loss: 0.005 total_reward [train:-1231.849 test:-] exploration:0.000: 100%|██████████| 200/200 [00:07<00:00, 28.04it/s]\n",
      "episode 165 avg_loss: 0.003 total_reward [train:-1337.975 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 37.06it/s]\n",
      "episode 166 avg_loss: 0.005 total_reward [train:-1375.750 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 32.02it/s]\n",
      "episode 167 avg_loss: 0.006 total_reward [train:-1410.368 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 33.69it/s]\n",
      "episode 168 avg_loss: 0.006 total_reward [train:-1286.003 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 35.32it/s]\n",
      "episode 169 avg_loss: 0.005 total_reward [train:-1447.557 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 29.49it/s]\n",
      "episode 170 avg_loss: 0.004 total_reward [train:-1499.565 test:-1424.894] exploration:0.000: 100%|██████████| 200/200 [00:07<00:00, 24.89it/s]\n",
      "episode 171 avg_loss: 0.006 total_reward [train:-1451.315 test:-] exploration:0.000: 100%|██████████| 200/200 [00:07<00:00, 27.14it/s]\n",
      "episode 172 avg_loss: 0.006 total_reward [train:-1485.607 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 31.55it/s]\n",
      "episode 173 avg_loss: 0.009 total_reward [train:-1430.433 test:-] exploration:0.000: 100%|██████████| 200/200 [00:07<00:00, 28.29it/s]\n",
      "episode 174 avg_loss: 0.005 total_reward [train:-1337.524 test:-] exploration:0.000: 100%|██████████| 200/200 [00:07<00:00, 40.37it/s]\n",
      "episode 175 avg_loss: 0.008 total_reward [train:-1467.721 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 35.47it/s]\n",
      "episode 176 avg_loss: 0.006 total_reward [train:-1494.818 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 36.53it/s]\n",
      "episode 177 avg_loss: 0.005 total_reward [train:-1491.380 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 25.08it/s]\n",
      "episode 178 avg_loss: 0.003 total_reward [train:-1509.269 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 31.30it/s]\n",
      "episode 179 avg_loss: 0.006 total_reward [train:-1389.536 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 29.73it/s]\n",
      "episode 180 avg_loss: 0.002 total_reward [train:-1530.149 test:-1529.230] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 30.34it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode 181 avg_loss: 0.005 total_reward [train:-1492.153 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 30.03it/s]\n",
      "episode 182 avg_loss: 0.007 total_reward [train:-1368.990 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 31.27it/s]\n",
      "episode 183 avg_loss: 0.003 total_reward [train:-1460.056 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 36.46it/s]\n",
      "episode 184 avg_loss: 0.004 total_reward [train:-1480.188 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 32.73it/s]\n",
      "episode 185 avg_loss: 0.004 total_reward [train:-1511.465 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 37.67it/s]\n",
      "episode 186 avg_loss: 0.005 total_reward [train:-1512.420 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 33.50it/s]\n",
      "episode 187 avg_loss: 0.005 total_reward [train:-1514.321 test:-] exploration:0.000: 100%|██████████| 200/200 [00:07<00:00, 27.82it/s]\n",
      "episode 188 avg_loss: 0.006 total_reward [train:-1508.484 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 33.20it/s]\n",
      "episode 189 avg_loss: 0.004 total_reward [train:-1505.489 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 41.35it/s]\n",
      "episode 190 avg_loss: 0.004 total_reward [train:-1503.518 test:-1501.442] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 32.01it/s]\n",
      "episode 191 avg_loss: 0.009 total_reward [train:-1509.066 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 34.14it/s]\n",
      "episode 192 avg_loss: 0.003 total_reward [train:-1288.030 test:-] exploration:0.000: 100%|██████████| 200/200 [00:07<00:00, 28.23it/s]\n",
      "episode 193 avg_loss: 0.006 total_reward [train:-1347.916 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 37.98it/s]\n",
      "episode 194 avg_loss: 0.005 total_reward [train:-1510.339 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 29.26it/s]\n",
      "episode 195 avg_loss: 0.003 total_reward [train:-1508.646 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 34.33it/s]\n",
      "episode 196 avg_loss: 0.010 total_reward [train:-1514.483 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 29.87it/s]\n",
      "episode 197 avg_loss: 0.006 total_reward [train:-1476.293 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 33.22it/s]\n",
      "episode 198 avg_loss: 0.002 total_reward [train:-1499.512 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 34.38it/s]\n",
      "episode 199 avg_loss: 0.005 total_reward [train:-1346.108 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 35.16it/s]\n",
      "episode 200 avg_loss: 0.006 total_reward [train:-1463.025 test:-1449.101] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 31.38it/s]\n",
      "episode 201 avg_loss: 0.006 total_reward [train:-1473.608 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 33.22it/s]\n",
      "episode 202 avg_loss: 0.002 total_reward [train:-1493.669 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 36.01it/s]\n",
      "episode 203 avg_loss: 0.004 total_reward [train:-1235.890 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 30.79it/s]\n",
      "episode 204 avg_loss: 0.006 total_reward [train:-1251.571 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 30.99it/s]\n",
      "episode 205 avg_loss: 0.004 total_reward [train:-1498.215 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 33.89it/s]\n",
      "episode 206 avg_loss: 0.006 total_reward [train:-1195.752 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 30.07it/s]\n",
      "episode 207 avg_loss: 0.004 total_reward [train:-1493.419 test:-] exploration:0.000: 100%|██████████| 200/200 [00:07<00:00, 26.45it/s]\n",
      "episode 208 avg_loss: 0.005 total_reward [train:-1246.509 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 30.06it/s]\n",
      "episode 209 avg_loss: 0.004 total_reward [train:-1243.200 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 33.98it/s]\n",
      "episode 210 avg_loss: 0.004 total_reward [train:-1279.301 test:-1279.273] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 38.03it/s]\n",
      "episode 211 avg_loss: 0.007 total_reward [train:-1229.225 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 30.74it/s]\n",
      "episode 212 avg_loss: 0.007 total_reward [train:-1242.437 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 31.89it/s]\n",
      "episode 213 avg_loss: 0.004 total_reward [train:-981.085 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 29.57it/s]\n",
      "episode 214 avg_loss: 0.003 total_reward [train:-1315.211 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 31.17it/s]\n",
      "episode 215 avg_loss: 0.011 total_reward [train:-1227.303 test:-] exploration:0.000: 100%|██████████| 200/200 [00:07<00:00, 25.94it/s]\n",
      "episode 216 avg_loss: 0.003 total_reward [train:-1245.744 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 39.24it/s]\n",
      "episode 217 avg_loss: 0.005 total_reward [train:-1203.900 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 32.35it/s]\n",
      "episode 218 avg_loss: 0.003 total_reward [train:-1191.515 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 34.55it/s]\n",
      "episode 219 avg_loss: 0.004 total_reward [train:-1185.001 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 27.03it/s]\n",
      "episode 220 avg_loss: 0.004 total_reward [train:-1208.441 test:-1245.760] exploration:0.000: 100%|██████████| 200/200 [00:08<00:00, 31.03it/s]\n",
      "episode 221 avg_loss: 0.006 total_reward [train:-1242.348 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 31.12it/s]\n",
      "episode 222 avg_loss: 0.004 total_reward [train:-1177.082 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 43.38it/s]\n",
      "episode 223 avg_loss: 0.004 total_reward [train:-1218.788 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 34.34it/s]\n",
      "episode 224 avg_loss: 0.005 total_reward [train:-1165.332 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 27.38it/s]\n",
      "episode 225 avg_loss: 0.004 total_reward [train:-1183.363 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 32.22it/s]\n",
      "episode 226 avg_loss: 0.003 total_reward [train:-1179.640 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 29.23it/s]\n",
      "episode 227 avg_loss: 0.005 total_reward [train:-1073.024 test:-] exploration:0.000: 100%|██████████| 200/200 [00:07<00:00, 28.46it/s]\n",
      "episode 228 avg_loss: 0.007 total_reward [train:-850.874 test:-] exploration:0.000: 100%|██████████| 200/200 [00:07<00:00, 28.52it/s]\n",
      "episode 229 avg_loss: 0.003 total_reward [train:-1157.913 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 30.45it/s]\n",
      "episode 230 avg_loss: 0.007 total_reward [train:-1154.254 test:-1142.706] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 28.84it/s]\n",
      "episode 231 avg_loss: 0.009 total_reward [train:-1181.723 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 32.64it/s]\n",
      "episode 232 avg_loss: 0.004 total_reward [train:-1175.722 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 31.69it/s]\n",
      "episode 233 avg_loss: 0.004 total_reward [train:-1568.123 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 37.27it/s]\n",
      "episode 234 avg_loss: 0.009 total_reward [train:-1223.243 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 31.39it/s]\n",
      "episode 235 avg_loss: 0.003 total_reward [train:-1068.677 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 32.14it/s]\n",
      "episode 236 avg_loss: 0.008 total_reward [train:-1195.834 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 31.41it/s]\n",
      "episode 237 avg_loss: 0.003 total_reward [train:-1170.419 test:-] exploration:0.000: 100%|██████████| 200/200 [00:07<00:00, 28.53it/s]\n",
      "episode 238 avg_loss: 0.005 total_reward [train:-1188.577 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 39.94it/s]\n",
      "episode 239 avg_loss: 0.006 total_reward [train:-1131.330 test:-] exploration:0.000: 100%|██████████| 200/200 [00:07<00:00, 27.88it/s]\n",
      "episode 240 avg_loss: 0.004 total_reward [train:-1189.888 test:-1122.338] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 31.73it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode 241 avg_loss: 0.004 total_reward [train:-1159.948 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 28.89it/s]\n",
      "episode 242 avg_loss: 0.005 total_reward [train:-1151.848 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 33.26it/s]\n",
      "episode 243 avg_loss: 0.004 total_reward [train:-1350.090 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 34.78it/s]\n",
      "episode 244 avg_loss: 0.006 total_reward [train:-1516.012 test:-] exploration:0.000: 100%|██████████| 200/200 [00:07<00:00, 27.40it/s]\n",
      "episode 245 avg_loss: 0.003 total_reward [train:-1163.722 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 36.57it/s]\n",
      "episode 246 avg_loss: 0.006 total_reward [train:-1160.268 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 34.44it/s]\n",
      "episode 247 avg_loss: 0.011 total_reward [train:-1109.434 test:-] exploration:0.000: 100%|██████████| 200/200 [00:07<00:00, 28.38it/s]\n",
      "episode 248 avg_loss: 0.004 total_reward [train:-1168.293 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 44.11it/s]\n",
      "episode 249 avg_loss: 0.004 total_reward [train:-1387.361 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 30.71it/s]\n",
      "episode 250 avg_loss: 0.005 total_reward [train:-1189.772 test:-1142.637] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 30.12it/s]\n",
      "episode 251 avg_loss: 0.005 total_reward [train:-1100.861 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 24.58it/s]\n",
      "episode 252 avg_loss: 0.006 total_reward [train:-1376.620 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 29.55it/s]\n",
      "episode 253 avg_loss: 0.003 total_reward [train:-1317.326 test:-] exploration:0.000: 100%|██████████| 200/200 [00:07<00:00, 27.65it/s]\n",
      "episode 254 avg_loss: 0.008 total_reward [train:-1488.098 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 30.15it/s]\n",
      "episode 255 avg_loss: 0.006 total_reward [train:-1103.766 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 31.17it/s]\n",
      "episode 256 avg_loss: 0.005 total_reward [train:-1027.416 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 31.87it/s]\n",
      "episode 257 avg_loss: 0.008 total_reward [train:-1431.301 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 38.05it/s]\n",
      "episode 258 avg_loss: 0.005 total_reward [train:-1401.035 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 26.50it/s]\n",
      "episode 259 avg_loss: 0.005 total_reward [train:-1078.140 test:-] exploration:0.000: 100%|██████████| 200/200 [00:07<00:00, 27.89it/s]\n",
      "episode 260 avg_loss: 0.005 total_reward [train:-1271.338 test:-1331.494] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 31.68it/s]\n",
      "episode 261 avg_loss: 0.005 total_reward [train:-980.041 test:-] exploration:0.000: 100%|██████████| 200/200 [00:07<00:00, 27.90it/s]\n",
      "episode 262 avg_loss: 0.010 total_reward [train:-1319.293 test:-] exploration:0.000: 100%|██████████| 200/200 [00:08<00:00, 23.20it/s]\n",
      "episode 263 avg_loss: 0.003 total_reward [train:-1642.024 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 29.14it/s]\n",
      "episode 264 avg_loss: 0.009 total_reward [train:-1160.983 test:-] exploration:0.000: 100%|██████████| 200/200 [00:07<00:00, 29.36it/s]\n",
      "episode 265 avg_loss: 0.007 total_reward [train:-1105.748 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 33.56it/s]\n",
      "episode 266 avg_loss: 0.005 total_reward [train:-1113.275 test:-] exploration:0.000: 100%|██████████| 200/200 [00:07<00:00, 25.80it/s]\n",
      "episode 267 avg_loss: 0.007 total_reward [train:-1504.774 test:-] exploration:0.000: 100%|██████████| 200/200 [00:07<00:00, 25.71it/s]\n",
      "episode 268 avg_loss: 0.005 total_reward [train:-1177.291 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 28.78it/s]\n",
      "episode 269 avg_loss: 0.008 total_reward [train:-1071.256 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 28.62it/s]\n",
      "episode 270 avg_loss: 0.006 total_reward [train:-1282.856 test:-1631.031] exploration:0.000: 100%|██████████| 200/200 [00:07<00:00, 26.42it/s]\n",
      "episode 271 avg_loss: 0.003 total_reward [train:-1572.596 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 30.78it/s]\n",
      "episode 272 avg_loss: 0.004 total_reward [train:-1599.651 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 31.01it/s]\n",
      "episode 273 avg_loss: 0.008 total_reward [train:-1602.913 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 29.09it/s]\n",
      "episode 274 avg_loss: 0.004 total_reward [train:-1545.285 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 35.77it/s]\n",
      "episode 275 avg_loss: 0.009 total_reward [train:-1487.626 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 32.63it/s]\n",
      "episode 276 avg_loss: 0.003 total_reward [train:-1463.070 test:-] exploration:0.000: 100%|██████████| 200/200 [00:07<00:00, 28.90it/s]\n",
      "episode 277 avg_loss: 0.013 total_reward [train:-1575.505 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 30.99it/s]\n",
      "episode 278 avg_loss: 0.003 total_reward [train:-1464.797 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 33.10it/s]\n",
      "episode 279 avg_loss: 0.016 total_reward [train:-1372.498 test:-] exploration:0.000: 100%|██████████| 200/200 [00:07<00:00, 24.08it/s]\n",
      "episode 280 avg_loss: 0.008 total_reward [train:-1339.101 test:-1495.301] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 29.13it/s]\n",
      "episode 281 avg_loss: 0.004 total_reward [train:-1468.971 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 29.40it/s]\n",
      "episode 282 avg_loss: 0.003 total_reward [train:-1246.405 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 30.90it/s]\n",
      "episode 283 avg_loss: 0.005 total_reward [train:-1501.066 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 26.60it/s]\n",
      "episode 284 avg_loss: 0.005 total_reward [train:-1288.095 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 31.61it/s]\n",
      "episode 285 avg_loss: 0.006 total_reward [train:-1131.094 test:-] exploration:0.000: 100%|██████████| 200/200 [00:07<00:00, 31.44it/s]\n",
      "episode 286 avg_loss: 0.004 total_reward [train:-1248.202 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 35.25it/s]\n",
      "episode 287 avg_loss: 0.004 total_reward [train:-1513.479 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 30.19it/s]\n",
      "episode 288 avg_loss: 0.007 total_reward [train:-1498.139 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 31.55it/s]\n",
      "episode 289 avg_loss: 0.008 total_reward [train:-1501.177 test:-] exploration:0.000: 100%|██████████| 200/200 [00:07<00:00, 27.68it/s]\n",
      "episode 290 avg_loss: 0.008 total_reward [train:-1495.648 test:-1245.906] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 29.89it/s]\n",
      "episode 291 avg_loss: 0.003 total_reward [train:-1220.405 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 29.94it/s]\n",
      "episode 292 avg_loss: 0.003 total_reward [train:-1507.824 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 29.09it/s]\n",
      "episode 293 avg_loss: 0.019 total_reward [train:-1383.670 test:-] exploration:0.000: 100%|██████████| 200/200 [00:07<00:00, 27.22it/s]\n",
      "episode 294 avg_loss: 0.003 total_reward [train:-1238.292 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 29.86it/s]\n",
      "episode 295 avg_loss: 0.012 total_reward [train:-1488.625 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 33.57it/s]\n",
      "episode 296 avg_loss: 0.004 total_reward [train:-1362.723 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 40.68it/s]\n",
      "episode 297 avg_loss: 0.007 total_reward [train:-1295.641 test:-] exploration:0.000: 100%|██████████| 200/200 [00:07<00:00, 28.30it/s]\n",
      "episode 298 avg_loss: 0.011 total_reward [train:-1368.937 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 34.87it/s]\n",
      "episode 299 avg_loss: 0.004 total_reward [train:-1521.760 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 34.62it/s]\n",
      "episode 300 avg_loss: 0.004 total_reward [train:-1330.108 test:-1500.218] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 23.65it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode 301 avg_loss: 0.006 total_reward [train:-1490.427 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 32.22it/s]\n",
      "episode 302 avg_loss: 0.005 total_reward [train:-1332.990 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 38.02it/s]\n",
      "episode 303 avg_loss: 0.003 total_reward [train:-1372.679 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 38.33it/s]\n",
      "episode 304 avg_loss: 0.004 total_reward [train:-1350.619 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 35.17it/s]\n",
      "episode 305 avg_loss: 0.004 total_reward [train:-1382.855 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 41.62it/s]\n",
      "episode 306 avg_loss: 0.005 total_reward [train:-1362.375 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 30.20it/s]\n",
      "episode 307 avg_loss: 0.006 total_reward [train:-1359.125 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 29.79it/s]\n",
      "episode 308 avg_loss: 0.006 total_reward [train:-1497.711 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 32.16it/s]\n",
      "episode 309 avg_loss: 0.005 total_reward [train:-1302.078 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 33.03it/s]\n",
      "episode 310 avg_loss: 0.005 total_reward [train:-1251.495 test:-1227.493] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 35.23it/s]\n",
      "episode 311 avg_loss: 0.004 total_reward [train:-1262.761 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 32.96it/s]\n",
      "episode 312 avg_loss: 0.008 total_reward [train:-1501.610 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 35.16it/s]\n",
      "episode 313 avg_loss: 0.004 total_reward [train:-1303.440 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 34.24it/s]\n",
      "episode 314 avg_loss: 0.005 total_reward [train:-1510.053 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 33.73it/s]\n",
      "episode 315 avg_loss: 0.003 total_reward [train:-1293.291 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 29.82it/s]\n",
      "episode 316 avg_loss: 0.004 total_reward [train:-1320.590 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 31.79it/s]\n",
      "episode 317 avg_loss: 0.010 total_reward [train:-1440.584 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 33.15it/s]\n",
      "episode 318 avg_loss: 0.004 total_reward [train:-1497.016 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 34.90it/s]\n",
      "episode 319 avg_loss: 0.003 total_reward [train:-1410.461 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 30.07it/s]\n",
      "episode 320 avg_loss: 0.004 total_reward [train:-1400.630 test:-1359.398] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 29.38it/s]\n",
      "episode 321 avg_loss: 0.005 total_reward [train:-1518.515 test:-] exploration:0.000: 100%|██████████| 200/200 [00:07<00:00, 28.30it/s]\n",
      "episode 322 avg_loss: 0.007 total_reward [train:-1342.162 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 29.90it/s]\n",
      "episode 323 avg_loss: 0.005 total_reward [train:-1432.401 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 30.12it/s]\n",
      "episode 324 avg_loss: 0.005 total_reward [train:-1366.937 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 36.07it/s]\n",
      "episode 325 avg_loss: 0.005 total_reward [train:-1386.972 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 31.98it/s]\n",
      "episode 326 avg_loss: 0.004 total_reward [train:-1472.365 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 32.20it/s]\n",
      "episode 327 avg_loss: 0.003 total_reward [train:-1411.543 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 34.67it/s]\n",
      "episode 328 avg_loss: 0.008 total_reward [train:-1424.034 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 30.91it/s]\n",
      "episode 329 avg_loss: 0.008 total_reward [train:-1345.054 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 40.80it/s]\n",
      "episode 330 avg_loss: 0.005 total_reward [train:-1318.874 test:-1352.007] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 38.50it/s]\n",
      "episode 331 avg_loss: 0.007 total_reward [train:-1289.938 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 35.17it/s]\n",
      "episode 332 avg_loss: 0.004 total_reward [train:-1398.047 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 29.58it/s]\n",
      "episode 333 avg_loss: 0.003 total_reward [train:-1378.728 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 33.71it/s]\n",
      "episode 334 avg_loss: 0.006 total_reward [train:-1373.174 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 28.60it/s]\n",
      "episode 335 avg_loss: 0.003 total_reward [train:-1445.982 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 33.06it/s]\n",
      "episode 336 avg_loss: 0.007 total_reward [train:-1519.419 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 32.06it/s]\n",
      "episode 337 avg_loss: 0.007 total_reward [train:-1463.844 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 31.25it/s]\n",
      "episode 338 avg_loss: 0.005 total_reward [train:-1490.971 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 33.89it/s]\n",
      "episode 339 avg_loss: 0.005 total_reward [train:-1496.609 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 37.81it/s]\n",
      "episode 340 avg_loss: 0.012 total_reward [train:-1424.758 test:-1496.190] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 28.26it/s]\n",
      "episode 341 avg_loss: 0.005 total_reward [train:-1503.954 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 33.17it/s]\n",
      "episode 342 avg_loss: 0.003 total_reward [train:-1492.033 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 33.56it/s]\n",
      "episode 343 avg_loss: 0.005 total_reward [train:-1516.214 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 33.86it/s]\n",
      "episode 344 avg_loss: 0.004 total_reward [train:-1513.533 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 38.77it/s]\n",
      "episode 345 avg_loss: 0.006 total_reward [train:-1422.379 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 35.41it/s]\n",
      "episode 346 avg_loss: 0.005 total_reward [train:-1493.253 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 32.17it/s]\n",
      "episode 347 avg_loss: 0.005 total_reward [train:-1492.189 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 31.73it/s]\n",
      "episode 348 avg_loss: 0.004 total_reward [train:-1412.435 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 33.62it/s]\n",
      "episode 349 avg_loss: 0.006 total_reward [train:-1389.724 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 33.93it/s]\n",
      "episode 350 avg_loss: 0.004 total_reward [train:-1434.930 test:-1504.945] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 31.99it/s]\n",
      "episode 351 avg_loss: 0.004 total_reward [train:-1394.798 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 29.85it/s]\n",
      "episode 352 avg_loss: 0.005 total_reward [train:-1553.445 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 23.55it/s]\n",
      "episode 353 avg_loss: 0.006 total_reward [train:-1732.667 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 35.01it/s]\n",
      "episode 354 avg_loss: 0.005 total_reward [train:-1183.986 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 39.35it/s]\n",
      "episode 355 avg_loss: 0.004 total_reward [train:-1146.562 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 37.41it/s]\n",
      "episode 356 avg_loss: 0.004 total_reward [train:-1140.809 test:-] exploration:0.000: 100%|██████████| 200/200 [00:07<00:00, 28.17it/s]\n",
      "episode 357 avg_loss: 0.011 total_reward [train:-1171.755 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 38.52it/s]\n",
      "episode 358 avg_loss: 0.005 total_reward [train:-1173.028 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 33.01it/s]\n",
      "episode 359 avg_loss: 0.004 total_reward [train:-1802.073 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 34.35it/s]\n",
      "episode 360 avg_loss: 0.003 total_reward [train:-1518.569 test:-1323.969] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 32.92it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "episode 361 avg_loss: 0.005 total_reward [train:-1689.263 test:-] exploration:0.000: 100%|██████████| 200/200 [00:04<00:00, 45.86it/s]\n",
      "episode 362 avg_loss: 0.007 total_reward [train:-1820.848 test:-] exploration:0.000: 100%|██████████| 200/200 [00:04<00:00, 41.05it/s]\n",
      "episode 363 avg_loss: 0.005 total_reward [train:-1882.832 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 31.90it/s]\n",
      "episode 364 avg_loss: 0.003 total_reward [train:-1399.143 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 35.88it/s]\n",
      "episode 365 avg_loss: 0.005 total_reward [train:-1289.636 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 27.03it/s]\n",
      "episode 366 avg_loss: 0.004 total_reward [train:-1503.275 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 32.33it/s]\n",
      "episode 367 avg_loss: 0.006 total_reward [train:-1518.743 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 31.31it/s]\n",
      "episode 368 avg_loss: 0.003 total_reward [train:-1470.078 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 31.22it/s]\n",
      "episode 369 avg_loss: 0.005 total_reward [train:-1517.173 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 34.59it/s]\n",
      "episode 370 avg_loss: 0.004 total_reward [train:-1380.152 test:-1487.609] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 30.43it/s]\n",
      "episode 371 avg_loss: 0.012 total_reward [train:-1500.840 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 31.20it/s]\n",
      "episode 372 avg_loss: 0.008 total_reward [train:-1134.935 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 38.28it/s]\n",
      "episode 373 avg_loss: 0.003 total_reward [train:-1070.234 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 29.77it/s]\n",
      "episode 374 avg_loss: 0.006 total_reward [train:-1043.180 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 37.14it/s]\n",
      "episode 375 avg_loss: 0.004 total_reward [train:-1140.276 test:-] exploration:0.000: 100%|██████████| 200/200 [00:04<00:00, 40.03it/s]\n",
      "episode 376 avg_loss: 0.003 total_reward [train:-1161.938 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 32.66it/s]\n",
      "episode 377 avg_loss: 0.004 total_reward [train:-1153.206 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 34.62it/s]\n",
      "episode 378 avg_loss: 0.018 total_reward [train:-1159.926 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 41.42it/s]\n",
      "episode 379 avg_loss: 0.004 total_reward [train:-1183.351 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 32.47it/s]\n",
      "episode 380 avg_loss: 0.005 total_reward [train:-1155.069 test:-1175.307] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 29.27it/s]\n",
      "episode 381 avg_loss: 0.011 total_reward [train:-1139.385 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 33.87it/s]\n",
      "episode 382 avg_loss: 0.005 total_reward [train:-1156.890 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 38.32it/s]\n",
      "episode 383 avg_loss: 0.009 total_reward [train:-1493.855 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 31.76it/s]\n",
      "episode 384 avg_loss: 0.003 total_reward [train:-1219.676 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 32.72it/s]\n",
      "episode 385 avg_loss: 0.004 total_reward [train:-1154.977 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 31.89it/s]\n",
      "episode 386 avg_loss: 0.014 total_reward [train:-1497.089 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 36.06it/s]\n",
      "episode 387 avg_loss: 0.005 total_reward [train:-1188.364 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 33.41it/s]\n",
      "episode 388 avg_loss: 0.004 total_reward [train:-1371.225 test:-] exploration:0.000: 100%|██████████| 200/200 [00:04<00:00, 41.54it/s]\n",
      "episode 389 avg_loss: 0.007 total_reward [train:-1545.905 test:-] exploration:0.000: 100%|██████████| 200/200 [00:04<00:00, 40.72it/s]\n",
      "episode 390 avg_loss: 0.003 total_reward [train:-1226.310 test:-1170.049] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 31.28it/s]\n",
      "episode 391 avg_loss: 0.004 total_reward [train:-1513.783 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 32.72it/s]\n",
      "episode 392 avg_loss: 0.005 total_reward [train:-1143.782 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 33.53it/s]\n",
      "episode 393 avg_loss: 0.008 total_reward [train:-1120.448 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 34.07it/s]\n",
      "episode 394 avg_loss: 0.006 total_reward [train:-1155.143 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 35.43it/s]\n",
      "episode 395 avg_loss: 0.003 total_reward [train:-1150.852 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 36.90it/s]\n",
      "episode 396 avg_loss: 0.009 total_reward [train:-1157.625 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 38.41it/s]\n",
      "episode 397 avg_loss: 0.007 total_reward [train:-1162.539 test:-] exploration:0.000: 100%|██████████| 200/200 [00:06<00:00, 31.87it/s]\n",
      "episode 398 avg_loss: 0.015 total_reward [train:-1494.190 test:-] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 41.43it/s]\n",
      "episode 399 avg_loss: 0.006 total_reward [train:-1150.851 test:-] exploration:0.000: 100%|██████████| 200/200 [00:04<00:00, 34.49it/s]\n",
      "episode 400 avg_loss: 0.004 total_reward [train:-1147.034 test:-1152.111] exploration:0.000: 100%|██████████| 200/200 [00:05<00:00, 35.43it/s]\n"
     ]
    }
   ],
   "source": [
    "ddpg.train(episode=400, episode_step=200, exploration_step=30000, min_exploration_rate=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1188.92223572\n"
     ]
    }
   ],
   "source": [
    "test_reward_list = ddpg.test()\n",
    "print(test_reward_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the test result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Total Rewards per Episode')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f390f908a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(test_reward_list)\n",
    "plt.xlabel(\"Episodes\")\n",
    "plt.ylabel(\"Total Rewards per Episode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
